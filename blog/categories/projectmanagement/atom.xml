<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ProjectManagement | TsaiKoga Blog]]></title>
  <link href="https://TsaiKoga.github.com/blog/categories/projectmanagement/atom.xml" rel="self"/>
  <link href="https://TsaiKoga.github.com/"/>
  <updated>2019-04-20T16:52:19+08:00</updated>
  <id>https://TsaiKoga.github.com/</id>
  <author>
    <name><![CDATA[TsaiKoga]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[宕机后的架构思考]]></title>
    <link href="https://TsaiKoga.github.com/blog/2019/04/18/dang-ji-hou-de-jia-gou-si-kao/"/>
    <updated>2019-04-18T10:24:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2019/04/18/dang-ji-hou-de-jia-gou-si-kao</id>
    <content type="html"><![CDATA[<h1>背景</h1>

<p>上个月公司服务器频繁宕机，第一次是因为日志撑爆了服务器，已经在[服务器日志空间解决方案-外挂磁盘]中解决了；</p>

<p>后面又有两次宕机，都是数据库 RDS 使用率太高导致的；</p>

<p>由于阿里云监控 RDS 报警不及时，所以比较难及时进行处理；</p>

<p>后来我使用了 processlist 查看：</p>

<p><code>sql
select id, db, user, host, command, time, state, info
from information_schema.processlist
where command != 'Sleep'
order by time desc
</code></p>

<p>可以实时的观测到是哪些 sql 现在执行慢，当然这些 sql 可能本身不慢，而是因为被慢 sql 阻塞了，导致执行时间太久；</p>

<p>我们可以通过 kill 命令将进程号杀掉（需要用有权限的账号登录）；</p>

<p>这些慢 sql 是 java 的新项目部署上去没有增加有效索引导致的，而新项目 和 已经稳定并且拥有大部分用户的 PHP 项目放在同一个 ECS，数据库也是同一台 RDS；
一个库占用了大部分 CPU 牵连另一个库执行 sql，造成部分 PHP 项目的用户开始投诉；</p>

<p>不过该问题已经得到解决，目前已经为不同项目拆分不同 ECS 和 不同的 RDS；</p>

<br>


<p>当前的 PHP 项目一些表的数据也都到达 2，3k万，现在 java 的项目有数据仓，有中台；
数据增长速度会比 PHP 项目快；</p>

<p>虽然已经稳定运行，但是这件事让我思考一个问题，如果以后用户级上去了，该怎么办？</p>

<br>


<h1>每秒请求数 qps</h1>

<p>前阵子看过一篇关于架构设计的文章，这里借用他的方法来设计为当前项目的架构做分析；</p>

<p>架构设计一般通过估量 qps，然后来设计架构；</p>

<p>首先我去查看项目的 qps，因为目前项目已经在线上，可以通过动态截取每秒日志请求数来估算 QPS：</p>

<p><code>sh
tail -f laravel-2019-04-01.log | cut -d ' ' f2 | uniq -c
</code></p>

<p>得出结论，大概 qps 为 100 左右；</p>

<p>目前 100 个请求每秒对于 8 核的 ECS 已经足够；</p>

<p>如果按照每个请求一秒要处理 3 个 sql 请求，那么对于 RDS 就是 300 请求每秒，也是足够的；</p>

<p>所以，就目前位置，服务器 ECS 和 数据库 RDS 都能够承载当前用户量访问。</p>

<br>


<br>


<h1>集群化部署</h1>

<h2>系统集群化部署</h2>

<p>那么以后销售人员推广力度变大，qps 将逐渐变大，那么一台 ECS 可能承载不了；</p>

<p>这时候我们可以加多一台 ECS 来拆分 qps；</p>

<p>假设 qps 为 500，我们使用“负载均衡”策略，将 qps 平分到两台 ECS 服务器上：</p>

<br>


<h3>架构</h3>

<pre><code>          |
        500/s
          |
          ↓
   { nginx 负载均衡 }
      |        |
   250/s     250/s
      |        |
      ↓        ↓
  { ECS1 }  { ECS2 }
      |        |
    750/s     750/s
      |        |
      +————————+
         |  |
         ↓  ↓
     { 数据库 RDS }
</code></pre>

<h3>简单实现：</h3>

<p>Nginx 通过 upstream 来给两台 ECS 分配权重，
以下是 tomcat + nginx 配置，PHP + nginx 也类似，只是换一下 tomcat_server 和 端口 即可
```</p>

<h1>负载均衡到 2 台 ECS 上，一个 130 的权重为 1/3，129 的权重为 2/3;</h1>

<p>upstream tomcat_server {
  server 192.168.200.130:8080 weight=10
  server 192.168.200.129:8080 weight=20
}</p>

<h1>监听 80 端口，并转发到 tomcat_server 这个 upstream</h1>

<p>server {
  listen 80
  location / {</p>

<pre><code>proxy_pass http://tomcat_server;
root html;
index index.html, index.htm;
</code></pre>

<p>  }
}
```</p>

<br>


<br>


<h2>数据库分库分表 + 读写分离</h2>

<p>但是现在有一个问题，就是数据量庞大，例如开单表已经到达了 26,934,626 条，虽然都有效的利用了索引，但是明显开单已经变慢；</p>

<p>再加上每天店铺小妹都在同一个高峰时段不停开单，若有卡顿，则可能会拖累其他 sql 执行，并且造成 CPU 使用率上升，从而宕机；</p>

<p>所以面临的问题主要是两个：</p>

<p>1：数据量太大，导致查询缓慢：</p>

<p>2：面对较大的 qps，例如前面 500 qps 已经分成两个请求 750/s 到 RDS 上；</p>

<p>当 qps 不断增加，ECS 都可以用负载均衡增加机器解决，但是系统层面上解决了，数据库层面上并发量到达 3000/s 就有问题了；</p>

<br>


<h3>解决方案：</h3>

<ol>
<li><p>通过将经常查询并且数据量大的表进行 “水平分割”；</p></li>
<li><p>分库分表 + 读写分离；
也就是把一个库拆分为多个库，部署在多个数据库服务上，这是作为主库承载写入请求的；然后每个主库都挂载至少一个从库，由从库来承载读请求。
此时假设对数据库层面的读写并发是 3000/s，其中写并发占到了 1000/s，读并发占到了 2000/s。
那么一旦分库分表之后，采用两台数据库服务器上部署主库来支撑写请求，每台服务器承载的写并发就是 500/s。每台主库挂载一个服务器部署从库，那么 2 个从库每个从库支撑的读并发就是 1000/s。</p></li>
</ol>


<br>


<h3>架构</h3>

<pre><code>                   |
              高峰 1000/s
                   ↓
           {  nginx 负载均衡  }
            |       |       |
          300/s   300/s   300/s
            ↓       ↓       ↓
   +———→ { ECS1 } { ECS2 } { ECS3 } ←————+
   |        |                 |          |
   |     500/s             500/s         |
 1000/s     ↓                 ↓       1000/s
   |    { 主库1 }          { 主库2 }       |
   |        ↓                 ↓           |
   +———— { 从库1 }         { 从库2 } ——————+
</code></pre>

<h3>简单实现</h3>

<h4>主从数据库：</h4>

<p>如果数据库是 ECS 自己创建的，需要通过开启 my.cnf 的 Binary log 功能实现 ；</p>

<p>如果是直接购买 RDS，可以购买两台，一台做主库，一台做从库，通过阿里云自带服务 DTS 同步数据；</p>

<h4>分库分表：</h4>

<p>最好的做法，是服务在 <strong>搭建之初</strong> 就设计为分库分表的存储模式，从根本上杜绝中后期的风险。
不过，会牺牲一些便利性，例如列表式的查询，同时，也增加了维护的复杂度。</p>

<p><strong>如何分表：</strong>
像 Laravel，我们可以事先写一个 model，对应这个 model 的所有分表，然后为这个 model 添加一个方法；</p>

<p>这个方法 通过传入查询条件，对每个表进行查询，然后 union 起来返回；</p>

<p>```php</p>

<pre><code>/* 传入查询的开始日期和结束日期用于计算跨越的表和达到约束表数据的目的。
   外部可以调整查询的列，还可以添加where条件
*/
public function setUnionAllTable($startTime = LARAVEL_START, $endTime = LARAVEL_START, $attributes = ['*'], $wheres = [])
{
    //约束条件
    $whereConditions = [];
    $wheres = array_merge([['time', '&gt;=', $startTime], ['time', '&lt;', $endTime]], $wheres);
    //时间戳转日期
    $startDate = date('Y-m', $startTime);
    $endDate = date('Y-m', $endTime);
    //涉及的表数组
    $tables = [];
    //循环where数组，格式是[['字段','表达式','值',' and|or '],['字段','表达式','值',' and|or ']]
    //例子[['beauty_uid', '=', '2011654', 'and']]
    foreach ($wheres as $val) {
        //组装每个where条件
        $val[2] = $val[2] ? $val[2] : "''";
        if (isset($val[3])) {
            $whereConditions[] = " {$val[3]} {$val[0]} {$val[1]} {$val[2]}";
        } else {
            $whereConditions[] = " and {$val[0]} {$val[1]} {$val[2]}";
        }
    }
    //循环开始日期和结束日期计算跨越的表
    for ($i = $startDate; $i &lt;= $endDate; $i = date('Y-m', strtotime($i . '+1month'))) {
        $tables[] = 'select ' . implode(',', $attributes) . ' from cdb_honey_log_' . date('Yn', strtotime($i)) . ' where 1' . implode('', $whereConditions);
    }
    //会得到每一个表的子查询，因为都有约束条件，所以每一个子查询得结果集都不会很多
    //用setTable的方法把这个子查询union all 后 as一个表名作为model的table属性
    //sql大概会是:(select xxx,xxx from honey_log_20177 where time &gt;= 开始日期 and time &lt; 结束日期 and xxx union all select xxx,xxx from honey_log_20178 where time &gt;= 开始日期 and time &lt; 结束日期 and xxx) as cdb_honey_log
    //核心是看你输入的开始日期和结束日期和约束条件，组装成一个union all的子查询然后作为table赋予model
    return $this-&gt;setTable(DB::raw('(' . implode(' union all ', $tables) . ') as cdb_honey_log'));
}
</code></pre>

<p>```</p>

<p>不过，最好还是使用 <strong>数据库中间件</strong>，数据量再大的时候，放到 Elasticsearch 里面，自带分片处理，交给他底层实现。</p>

<br>


<br>


<h2>缓存</h2>

<p>当 qps 再次上升，系统层面可以加机器，但是数据库其实本身不是用来承载高并发请求的，</p>

<p>所以通常来说，<strong>数据库单机每秒承载的并发就在几千的数量级</strong>，而且数据库使用的机器都是比较高配置，比较昂贵的机器，成本很高。；</p>

<p>或者原先没有分库分表，想分库加机器又觉得贵；</p>

<p>对于这两个问题，可以通过引入缓存解决；</p>

<p>根据 <strong>“二八定律”</strong>，80%的请求只关注在20%的热点数据上。因此，我们应该建立 服务器 和 数据库 之间的缓存机制。</p>

<p>这种机制，可以用磁盘作为缓存，也可以用内存缓存的方式。通过它们，将大部分的 <strong>热点数据查询</strong>，阻挡在数据库之前;</p>

<p>可以根据系统的业务特性，对那种写少读多的请求，引入缓存集群。</p>

<p>写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，这里可以使用 Memcached 或是 Redis 实现；</p>

<p>像前面架构图，读请求目前是每秒 2000/s，两个从库各自抗了 1000/s 读请求，但是其中可能每秒 1800 次的读请求都是可以直接读缓存里的不怎么变化的数据的，</p>

<p>剩下落到数据库的只有 200 次；</p>

<br>


<h3>架构</h3>

<pre><code>                       |
                  高峰 1000/s
                       |
                       ↓
             {  nginx 负载均衡  }
               |       |       |
             300/s   300/s   300/s
               ↓       ↓       ↓
+——————+——→ { ECS1 } { ECS2 } { ECS3 } ←————+———————+
|      |        |                 |         |       |
|      |     500/s             500/s        |       |
|    100/s      ↓                 ↓        100/s    |
|      |    { 主库1 }          { 主库2 }      |      |
|      |        |                 |          |      |
|      |       同步              同步         |      |
900/s  |        ↓                 ↓          |    900/s
|      +——  { 从库1 }         { 从库2 } ——————+      |
|                                                   |
+——————————————————— { 缓存集群 } ———————————————————+
</code></pre>

<p>参考：<a href="http://www.php.cn/linux-417207.html">http://www.php.cn/linux-417207.html</a></p>

<br>


<br>


<h2>消息中间件集群</h2>

<p>上面对读的数据做了缓存，那么如果 写操作 比较多，那该怎么办，不可能一直加机器吧？</p>

<p>这里我们要引入 消息中间件集群，例如 RabbitMQ，他是非常好的做写请求异步化处理，实现 <strong>削峰填谷</strong> 的效果。</p>

<h3>架构</h3>

<pre><code>                       |
                  高峰 1000/s
                       |
                       ↓
             {  nginx 负载均衡  }
               |       |       |
             300/s   300/s   300/s
               |       |       |   +————————————————————————————+
               ↓       ↓       ↓   |                            |
+——————+——→ { ECS1 } { ECS2 } { ECS3 } ←————+———————+           |
|      |        |                 |         |       |     { 消息中间件 MQ }
|      |     500/s             500/s        |       |           |
|      |        |                 |         |       |    削峰填谷 100/s 请求慢慢写
|    100/s      ↓                 ↓        100/s    |           |
|      |    { 主库1 }          { 主库2 } ←————+——————+———————————+
|      |        |                 |          |      |
900/s  |        ↓                 ↓          |    900/s
|      +——  { 从库1 }         { 从库2 } ——————+      |
|                                                   |
+——————————————————— { 缓存集群 } ———————————————————+
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[前后端分离]]></title>
    <link href="https://TsaiKoga.github.com/blog/2019/04/14/qian-hou-duan-fen-chi/"/>
    <updated>2019-04-14T12:00:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2019/04/14/qian-hou-duan-fen-chi</id>
    <content type="html"><![CDATA[<h3>目录</h3>

<h4><a href="#1">一、模板引擎</a></h4>

<h4><a href="#2">二、单页面应用 或 API</a></h4>

<h4><a href="#3">三、前端 MVC 模式</a></h4>

<h4><a href="#4">四、前端 MVVM 模式</a></h4>

<h4><a href="#5">五、Nodejs 前后端分离</a></h4>

<h2 id="1"> 一、模板引擎</h2>


<ul>
<li>ERB: 前端渲染引擎，可以将后端传来的数据渲染注入到前端 HTML 中，也可以帮它叫做 ModelAndView（与 MVVM 的View-Model有区别，View-Model 是简化 Controller，有逻辑，负责 View 和 Model 的交互，而这里只是 Model 数据与 View 强绑定而已）；</li>
<li>JS: 除了实现一些前端效果，还需要用 ajax 发起对后台的请求；</li>
</ul>


<br>


<p>我还记得大三的时候，接触 Rails 框架，那时候 Rails 已经推出了 Assets 功能，
所有 CSS / JS 放在 assets/ 目录中，
html.erb 放在 views/ 目录；</p>

<p>然后通过编译，前端样式 assets/*.css 文件最终生成 application.css 放在了 public/ 目录中；
前端 JS assets/*.coffee 文件最终生成 application.js 也放在 public/ 目录下；
而 views/*.html.erb 文件编译后变成纯 html 调用；
目前 PHP 的 Laravel 框架也是如此；</p>

<br>


<p><strong>优点：</strong></p>

<p>形成的是带有动态数据的html，比较有利于SEO</p>

<p><strong>缺点：</strong></p>

<p>前后端内容实际上没有隔离；所以一般做 Rails 的人既要会前端，又要会后端；</p>

<p>前端需要搭建整个 Rails 或者 Laravel 环境；</p>

<br>




<h2 id="2"> 二、单页面应用 或 APP</h2>


<ul>
<li>单页面应用，其实就是所有请求都是 Ajax，这样解决了前面提到的模板引擎问题；</li>
<li>开发 APP，前端开发 H5、IOS、Android 等，后端只需要开发 API 返回前端需要的 json 数据；</li>
</ul>


<br>


<p>记得刚进入公司做后端 API 开发的时候，发现很多 vue 页面还是通过上诉模板方式与 Laravel 糅合在一起；
然后前端文件会存放在后端 Laravel 项目仓库中；
后来我们把他分割开，前端单独起一个项目仓库，然后服务器编译完再复制到后端 Laravel 项目下的 Public/目录中；
虽然还是没有完全分离开，但是前端已经不需要后端语法，直接就是访问后端 API 接口即可；</p>

<br>


<p><strong>优点：</strong></p>

<p>前端不需要懂后端的语法，不用学习像 ERB 这样的模板引擎语法，</p>

<p>只需要通过 ajax 请求后端，后端返回后对返回的 json 数据做处理；</p>

<p><strong>缺点：</strong></p>

<p>前端逻辑越来越重，越来越复杂，浏览器端 和 客户端 逻辑复杂；</p>

<p>不利于 SEO；</p>

<br>




<h2 id="3"> 三、前端 MVC 模式</h2>


<p>当初在大三的时候，在实验室使用 Extjs，那时候 Extjs 开始走 MVC 架构，
然后毕业答辩时提到前端 MVC，而老师竟然说前端没有 MVC ，后端才有 MVC，
这里就来讲讲什么是前端 MVC，</p>

<p>前端 MVC 和后端 MVC 类似，</p>

<ul>
<li>Model 用来存放数据对象；</li>
<li>View 用来呈现给用户，一般由 HTML/CSS/JS 组成；</li>
<li>Controller 用来从 View 获取事件和输入，并进行处理，相应更新后更新视图；</li>
</ul>


<br>


<p><strong>优点：</strong></p>

<p>分工明确，可以开发并行；</p>

<p><strong>缺点：</strong></p>

<p>Controller 要自己写，大量操作 DOM，页面渲染速度降低；
操作冗余，代码难以维护；</p>

<br>




<h2 id="4"> 四、前端 MVVM 模式：</h2>


<p>ViewModel 代替了 Controller；</p>

<ul>
<li>Model 用来存放数据对象；</li>
<li>View 用来呈现给用户，一般由 HTML/CSS/JS 组成；</li>
<li>View-Model：简化的 Controller，为 View 提供处理好的数据，view 绑定 view-model，视图与数据模型强耦合。数据的变化实时反映在 view 上，不需要手动处理；</li>
</ul>


<br>


<p>解决了 MVC 模式的痛点，Controller 大量逻辑被简化，不需要大量操作 DOM 了；
View 和 Model 没有直接联系，是通过 View-Model 进行交互的；</p>

<br>


<p><strong>优点：</strong></p>

<p>不需大量 DOM 操作，前端工作减少，逻辑清晰；</p>

<p><strong>缺点：</strong></p>

<p>不利于 SEO；</p>

<br>




<h2 id="5"> 五、Nodejs 前后端分离：</h2>


<p>我们公司已经使用了 Vue 作为前端，一个 MVVM 模式的框架，
但是，我们还是会经常遇到各种问题；</p>

<br>


<p><strong>例如：</strong></p>

<ol>
<li><p>页面设计逻辑例如循环构造呈现的 JSON 数据，要么得前端处理，要么后端处理，一般都是前端处理，前端所需的排序功能、筛选功能，
以及到了视图层的页面展现，也许都需要对接口所提供的数据进行二次处理。数据量一大便会浪费浏览器性能，也造成代码难以维护，很多时候无法通用；</p></li>
<li><p>多端产品 APP 会遇到接受格式不一致，像是 H5 可以接受 BOOLEAN 字段，而 IOS 端只能通过 1 或 0 改变；</p></li>
</ol>


<br>


<p>我们把原先的 MMVM 模式作为前端的 UI 层；
然后将 Nodejs 起的服务作为前端服务层，这个前端 Server 层需要部署在服务器上；</p>

<p>前端 UI 层：用来处理浏览器层的展现逻辑。通过 CSS 渲染样式，通过 JavaScript 添加交互功能；
前端 Server 层：处理路由、模板、数据获取、cookie 等，路由完全前端控制，所以无论是 单页面 还是 多页面，前端都可以自由调控；</p>

<br>


<p><strong>优点：</strong></p>

<p>解决第 1 点问题：后端可以只做自己的事情，数据直接成为 json 发送给前端，前端 Nodejs 处理 json 逻辑，
Node Server 层放在服务器上，不会造成浏览器资源浪费；</p>

<p>解决第 2 点问题：使用 Node Server 层可以支持多端开发需要的内容不一致问题，H5 能处理 BOOLEAN 值，IOS 无法处理的情况；</p>

<p><strong>缺点：</strong></p>

<p>前端所需要了解服务端编程，所学内容增加，是基于 Nodejs 的全栈开发；</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[录单APP项目中的问题]]></title>
    <link href="https://TsaiKoga.github.com/blog/2018/10/28/lu-dan-appxiang-mu-zhong-de-wen-ti/"/>
    <updated>2018-10-28T15:46:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2018/10/28/lu-dan-appxiang-mu-zhong-de-wen-ti</id>
    <content type="html"><![CDATA[<h2>目录</h2>

<h4><a href="#1">分页重复数据问题</a></h4>

<h4><a href="#2">防止订单重复问题</a></h4>

<h4><a href="#3">订单号唯一问题</a></h4>

<h4><a href="#4">Web端报表系统使用导致APP端使用卡顿</a></h4>

<br/>


<br/>




<h2 id="1">分页重复数据问题</h2>


<hr />

<h4>背景：</h4>

<p>先解释一下，我们 app 项目中有一个录入订单模块，在这里每个店铺的工作人员会因为客户下单，在当天不停的进行录单；</p>

<p>这些订单按照当天的顺序形成一个单号，例如1，2，3，4&hellip; &hellip; 就这样；</p>

<p>app 中还有一个功能，就是插单，也就是如果有一张单据昨天忘记录入，那么可以添加插单时间到昨天，那么这张订单就插入了昨天；</p>

<p>但是，录单的工作人员有几个人，也就是同时有人会刷新这个页面，看到订单列表；</p>

<p>因为 app 是下拉刷新，加载第二页数据，并且是按照单据倒叙排列的，最先出现的是最新的单据；</p>

<p>这时候员工A如果开单到 25 号单据，然后再开第26的时候，员工B想要刷新第二页（按照每10张一页），那么本来应该看到的是15号单开始的第二页，</p>

<p>由于员工A完成26号单，这时候刷出来的是16号单开始的第二页，也就是25,24,23,&hellip;,16,16,15,14,&hellip;中间重单了；</p>

<br/>


<h4>解决方法：</h4>

<p>为了防止这种现象，必须在后台增加一个 <strong>过滤条件</strong>；</p>

<p>因为由时间排序，那么只要拿创建时间 <code>created_at</code> 与 前端传来查询时间 <code>search_at</code> 进行比较就可以筛选出第二页；</p>

<p>由于还有插单，所以插单的时间绝对不能覆盖创建时间 <code>created_at</code>，要有一个插单时间 <code>inserted_at</code>，这样排序用 <code>inserted_at</code> 来排序即可；</p>

<br/>


<br/>




<h2 id='2'>防止订单重复问题</h2>


<hr />

<h4>背景：</h4>

<p>由于这是一个给批发市场店铺的 app ；所以批发市场的店铺人员有限，但每天的订单数量又比较多，</p>

<p>这时候员工录入订单往往快速而又烦躁，对订单开单后可能会不停点击提交；虽然 IOS 端和 Android 端以对点击按钮做了屏蔽；</p>

<p>但是还是无法百分百杜绝一个单重复性提交；</p>

<p>这时候需要前端和后端配合一起防止同一张订单重复问题；</p>

<br/>


<h4>解决方法：</h4>

<p>前端给订单生成一个唯一码，一般用时间戳+随机数生成，这里我们用单词 exist_flag 代替；</p>

<p>然后前端发出请求，带上这个参数到后端；</p>

<p>后端接收到请求后首先将其用 redis 进行检验判断是否重复；</p>

<p>```php
if (Redis::get(&lsquo;orders:&rsquo;. $user_id . &lsquo;&ndash;&rsquo; . $exist_flag)) {</p>

<pre><code>return $this-&gt;fail(self::ERROR_CODE, "你还有订单正在进行中，请勿重复提交");
</code></pre>

<p>} else {</p>

<pre><code>Redis::set('orders:'. $user_id . '-' . $exist_flag, 1, 180);
</code></pre>

<p>}
```</p>

<br/>


<br/>




<h2 id='3'>订单号唯一问题</h2>


<hr />

<h4>背景：</h4>

<p>正如前面所提到的，订单按照每日生成唯一的订单号1,2,3,4,5 &hellip;&hellip;；</p>

<p>这是针对当天唯一的号码，并且当天不能重复，并且生成单据最好能较快，不要因为顺序问题影响体验；</p>

<br/>


<h4>解决方法：</h4>

<p>利用联合唯一索引来解决；</p>

<p>例如单号字段为 <code>transaction_daily_serial</code>, 时间为 <code>inserted_at</code></p>

<p>这里使用插单是插入选择日期的最后单据，因为这样不会导致重新更改其他单号；</p>

<p>那么联合唯一索引：</p>

<p><code>sql
alter table transaction add unique index daily_sel_ins_at(transaction_daily_serial, inserted_at);
</code></p>

<br/>


<br/>




<h2 id='4'>Web端报表系统使用导致APP端使用卡顿</h2>


<hr />

<h4>背景：</h4>

<p>APP 作为一个有点类似 ERP 的在线客户端，客户需要一些导出的Excel报表数据，包括（出入库数据，货品数据，订单总览）等等内容；</p>

<p>但由于数据内容非常庞大，并且客户不想要分批下载，他要一张excel展示所有时间段的数据；一开始数据量不多的时候，系统也没有为他们加时间限制；</p>

<p>后期，数据库数据量已经达到10G以上的时候，一段时间在业务高峰期出现 app 使用卡顿现象；</p>

<p>通过查询后台日志，我发现在这些卡顿时间都出现报表导出接口；</p>

<p>并且 APP 和 web 报表系统 是放在同一台服务器上；</p>

<br/>


<h4>解决方法：</h4>

<p>预想方案是有以下几个：</p>

<ol>
<li><p>分库【主从数据库】：因为 web 报表系统是查询数据，导出数据的系统，所以是只读系统，而 APP 是可读可写的；
分库可以保证 web 报表操作不影响 APP 手机端；</p></li>
<li><p>数据归档：将旧数据进行归档存储；</p></li>
<li><p>解决慢查询SQL</p></li>
<li><p>限制导出数据大小</p></li>
</ol>


<br/>


<p>由于公司项目较多，经费有限，无法再提供多一台服务器来专门用作 web 报表系统，所以方案一被取消；</p>

<p>数据归档虽然 CTO 答应采纳，但是当务之急是先解决目前问题，所以先从 方案三 和 方案四 下手；</p>

<p>方案三：通过阿里云的慢查询日志，定位到 SQL 语句，从而定位代码段；大部分慢查询可以通过添加联合索引解决；
但是一部分 smelly 的 SQL ORM 旧代码，就得重新编写优化；</p>

<p>方案四：根据客户需求和对应一个月的单据数量，给出最多只能下载一个月的数据；</p>

<br/>


<br/>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[公司项目中 Git 的使用方法]]></title>
    <link href="https://TsaiKoga.github.com/blog/2016/08/06/gong-si-xiang-mu-zhong-git-de-shi-yong-fang-fa/"/>
    <updated>2016-08-06T16:10:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2016/08/06/gong-si-xiang-mu-zhong-git-de-shi-yong-fang-fa</id>
    <content type="html"><![CDATA[<p>Git 是开源的分布式版本控制器，用于敏捷高效地处理任何或小或大的项目。</p>

<p>它被应用到很多 Rails 开发项目中。 公司对于 Git 也有适合的一套用法。</p>

<h4>背景</h4>

<hr />

<p>首先我来介绍一下公司的大致情况，然后阐述一下公司如何用Git进行工作：</p>

<p>我们公司是一家外企电商平台，产品在国外销售，技术部在中国，所以会有时差。面对这类问题，我们技术部这边对项目进行开发完善，
确定每周二的一个时间点为项目上线时间（因为这个时间点用户量极少），所有大改动和新功能都会在本周的这个时间点上线，我们称之为【常规上线】。
对于项目突然出现的 Bug ，或是上线后出现的 Bug，我们也会更改然后上线，这次上线属于当天的紧急上线，我们称之为【紧急上线】，取名为Hot Fix。</p>

<p>OK，接着来看看我们是如何使用 Git 进行如上的上线操作的。</p>

<h3>操作流程</h3>

<hr />

<h4>分支介绍</h4>

<p>先来看看我们项目主要的分支吧：</p>

<ul>
<li><p>master 主分支，用来部署周二的常规上线。</p></li>
<li><p>release 发布分支，这个分支的代码一定是生产环境下的分支（代码最新），用于切除 Hotfix 分支，作紧急上线处理。</p></li>
<li><p>testing 常规上线的测试分支，这里的代码用于测试，周二常规上线后可以删除后重建；不与master相同，测试完此分支与master分支无关；
用于当测试出现 BUG，修复很多次，最后测试通过；本地可以将最后通过的commits都合并为一个commit提交到master，保证commit的整洁，减少冲突。</p></li>
</ul>


<h4>常规上线</h4>

<p>接着，我们来看看如何常规上线，假设这周我有一个任务要完成，从 master 切出一个分支叫做 develop
``` sh</p>

<pre><code>git checkout -b develop
git commit -m "First Commit"
git push origin develop
</code></pre>

<p>```</p>

<p>然后周二正式上线，我们周一先将自己的分支本地测完，然后“合并”到公共的 testing 分支【记住是merge哦，不是rebase】；
``` sh</p>

<pre><code>git checkout testing                # from develop to testing
# git merge develop                 # 这里一般是发到 github 上给别人 pr，或是发到gitlab上给别人 mr
git push origin testing             # 如果是通过 gitlab/github mr/pr 后，这里将是 git pull origin testing
BRANCH=testing cap staging deploy   # 这里的 BRANCH 是通过 .bashrc 设置环境变量，deploy/staging.rb 中 set :branch, ENV["BRANCH"] || "master"
</code></pre>

<p>```</p>

<h4>注意事项 （merge 和 rebase）</h4>

<blockquote><p>有个问题需要注意，曾经我将我的代码rebase到testing上；</p>

<pre><code>git checkout testing
git rebase develop
</code></pre>

<p>rebase 会将 testing 和 develop 两个分支中的commit整理成 testing 一个分支，但是当两个分支中有一个commit发生冲突的时候
<img src="/images/posts/2016-08-06/git-rebase.png" title="rebase的图示" alt="git rebase" /></p>

<p>这个冲突如上图，来自于 develop 的 commit，你将它 rebase 到了 testing 上，正当你觉得一切顺利的时候；</p>

<p>你想要 push 你的代码到远程的 testing，你会发现需要 pull 代码，然而当你 pull 代码后，你又发现原来的冲突，然后解决冲突，然后再 pull 代码，这样无限循环下去&hellip;</p>

<p>这是因为远程的 testing 就是没解决冲突前的 testing 分支，你 rebase 后解决冲突的 commit 是 develop 的commit，这样你再次拉代码下来，冲突又再次出现了。</p></blockquote>

<p>所以，使用“merge”！这里 merge 后，develop 的 commit3 会与 testing 产生冲突，解决完冲突后，merge 不像 rebase 会把解决完的放在原来的 commit3 上，而是你需要
新提交一个解决冲突后的 commit【我们叫它commit4】，这样就 pull 的代码遇到 commit4，发现已被解决，就没有冲突了。</p>

<h4>紧急上线 Hotfix</h4>

<p>看到上面的常规上线，我们结束了周二的工作任务；周三来了，你来到办公室，发现昨天上线的内容还需要修改，并且必须在今天上线。这时候我们需要如下分支：</p>

<ul>
<li><p>release 分支， 周二从 master 分支部署到正式服务器后，将 master 代码 merge release 分支，release上的代码即代表着线上的最新代码。</p></li>
<li><p>hotfix160803 分支，从名字可以看出 hotfix + 日期，这个是从 release 切出来的，像testing分支一样，让所有要紧急发布的程序员将今天自己的分支合到这里进行测试。</p></li>
</ul>


<p>具体操作就是
1. 首先我们从 release 下载线上的代码 <code>git pull origin release:release</code>
2. release 分支切出一个 hotfix 分支 <code>git checkout -b hotfix160803</code>
3. 提交 hotfix160803 到远程，让大家可以合并代码
4. 建立自己的紧急开发分支 <code>git checkout -b hotfix-dev</code></p>

<p>如果已经有人提交了hotfix160803，则只需要 pull 下来，然后建立自己的分支开发。</p>

<p>接下来改完代码后的操作其实和常规上线一样。
``` sh</p>

<pre><code>git push hotfix-dev
</code></pre>

<p>```</p>

<p>gitlab 或 github 上 mr 或 pr
``` sh</p>

<pre><code>git checkout hotfix160803
git pull hotfix160803 # 将合并后的代码拉下来
BRANCH=hotfix160803 cap staging deploy
</code></pre>

<p>```</p>

<p>测试完毕后，将 hotfix160803 merge 到 release，发布release。</p>

<p>忙碌的一天就结束了。</p>

<h4>关于 Capistrano 的代码</h4>

<p>你的代码放在 gitlab 上面，项目运行在某个服务器A上，你将代码提交到 gitlab 上，然后 cap deploy；
其实cap deploy 是通过 clone 你的 gitlab 上的代码到服务器A上的</p>

<p>关于抽出逻辑，制作一个功能，其他传入简单参数，
关于方法里面，只有if，那干脆将if放方法外面；
关于需求，通过每个条件都列出来检查。
对于更改数据，记住留份log作为备份，将数据记录下来，以便回滚。</p>

<h4>经常使用的 Git 命令</h4>

<p>``` sh</p>

<pre><code>git checkout -b testing         # 新建分支testing 并切换到上面

git commit -m "Koga"            # commit
git commit --amend              # 将 add 的新修改也提交到之前的commit，并且可以更改commit名称

git pull origin master:master   # 拉远程的master到本地master，如果本地没有，则新建并拉代码下来，并且所在的分支也会拉master的内容下来，可以将其add 后checkout掉
git push origin master          # 提交到远程master分支，如果git push -f origin master，将强制提交

git rebase master               # 将当前分支与master合成一条
git reset HEAD~1                # 重置 上一个 commit，但是修改内容还是保留，只是还没commit
git merge master                # 将master合并到当前分支

git branch                      # 显示所有分支
git branch -D testing           # 删除 testing 分支
git branch -m dev               # 更改分支名称

git stash                       # 将更改内容暂存
git stash pop                   # 将暂存内容弹出
git stash clear                 # 清除暂存内容
</code></pre>

<p>```</p>

<p>让 bash 显示当前Git的分支及当前路径（如果有python的virtualenv，也显示在开头）：</p>

<p>``` sh</p>

<h6>#</h6>

<h1>shell obtain the git&rsquo;s current branch name</h1>

<h6>#</h6>

<p>find_git_branch() {
  local dir=. head
  until [ &ldquo;$dir&rdquo; -ef / ]; do</p>

<pre><code>if [ -f "$dir/.git/HEAD" ]; then
  head=$(&lt; "$dir/.git/HEAD")
  if [[ $head = ref:\ refs/heads/* ]]; then
    git_branch="[${head#*/*/}]"
  elif [[ $head != '' ]]; then
    git_branch="[no branch]"
  else
    git_branch="[unknow]"
  fi
  return
fi
dir="../$dir"
</code></pre>

<p>  done
  git_branch=&lsquo;&rsquo;
}
PROMPT_COMMAND=&ldquo;find_git_branch; $PROMPT_COMMAND&rdquo;
export PS1=&ldquo;(<code>basename \"$VIRTUAL_ENV\"</code>)\u@\h:\w\$git_branch\$ &rdquo;
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[敏捷开发]]></title>
    <link href="https://TsaiKoga.github.com/blog/2014/02/25/min-jie-kai-fa/"/>
    <updated>2014-02-25T13:23:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2014/02/25/min-jie-kai-fa</id>
    <content type="html"><![CDATA[<p><img src="/images/posts/2014-02-25/minjie.jpg" title="敏捷开发图" alt="图片无法显示" /></p>

<h5>敏捷开发的定义：</h5>

<p>是一种<strong>以人为核心、迭代、循环渐进的开发方法</strong>。在敏捷开发中项目被切分为多个子项目，各个子项目的成果都经过测试，具备集成和可运行的特征。简而言之，就是把一个大项目切分成多个<strong>相互联系但可独立运行的子项目</strong>，并<strong>分别完成</strong>。在此过程软件一直处于可使用状态。</p>

<h5>敏捷开发 5 大价值观</h5>

<ol>
<li>沟通: 团队内部的开发人员之间沟通。</li>
<li>简单: 就是指简单的建模，如画一两张图表来代替几十甚至几百行的代码。</li>
<li>反馈: 过度自信是编程的职业病，反馈则是其处方。</li>
<li>勇气: 当你的决策证明是不合适的时候，你就需要做出重大的决策，放弃或重构你的工作，修正你的方向。</li>
<li>谦逊: 这个就不用我解释了。</li>
</ol>


<h5>敏捷开发核心做法</h5>

<ol>
<li>测试驱动开发</li>
<li>结对编程: 指<strong>两位程序员</strong>肩并肩地坐在同一台电脑前<strong>合作完成</strong>同一个设计、同一个算法、同一段代码或同一组测试。</li>
<li>持续集成:</li>
<li>每日站立会议</li>
<li>共同拥有代码</li>
<li>系统隐喻</li>
</ol>


<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了敏捷开发模式，目前所具有的开发模式还有好几种,如：瀑布模型，快速原型模型，增量模型，螺旋模型，喷泉模型。
 我在大学的实验室中使用 Rails 框架进行开发，使用的是敏捷开发模式。虽然如此，但是我们团队的敏捷开发还是带有其他模型的特征，可能因为我们还是学生团队，不是一个真正意义上的商业团队(我们平常还必须上课)。</p>

<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我先通过我们团队负责的一个项目（在这里我们叫它为ce）来阐述，我们为什么不是真正的敏捷，而是有有快速原型和增量的特征的敏捷，或者说我们是采用混合模式。</p>

<p><span style="text-align:center"><img src="/images/posts/2014-02-25/zengliang.jpg" title="增量模型图" alt="图片无法显示" /></span></p>

<ol>
<li><p>ce 首先通过实现前台大部分界面（没有功能）的<strong>样品给客户观看并给予讲解</strong>。客户可以清楚的看到有具体形态而无功能的样品，从而有助于客户提出有<strong>针对性的修改意见</strong>。而参与调研的师兄们对<strong>样品进行再次修改</strong>，并再次呈现给客户看，直到双方达成共识为止；之后师兄们就对这些调研后的资料进行讨论并据此形成<strong>规格说明文档</strong>（我们的规格说明文档是前台界面的图片，并用文字等方式对其功能进行阐述，当然还有一些流程图），然后把之前做的不具有功能的<strong>样品抛弃</strong>。很明显这是<strong>结合了快速原型模型</strong>，从而得到它的<strong>优点</strong>：规格说明文档<strong>正确的描述客户的需求</strong>，减少了设计和编码阶段发生的可能性错误。</p></li>
<li><p>当进入开发阶段时，团队要求将这个 ce 项目分成三期；每期有几条流程，而各个阶段的流程互不影响。并在第一期开发结束后部署给企业使用，这样企业就能拥有<strong>充裕的时间学习和适应</strong>此系统,减少一个新系统可能给客户组织带来的冲击。第二期进行开发直至完成后再部署给企业，这样企业已经事先使用过系统，对系统的排斥性不会那么强了。<strong>增量模型是将软件产品作为一系列的增量构件来设计，编码，集成和测试</strong>。而 ce 的这种开发方式明显和增量模型类似,当然，也可以说是<strong>敏捷开发的增量交付</strong>。</p></li>
<li><p>最后，我想要通过实验室的 ce 项目来说明敏捷开发的特征。</p></li>
</ol>


<p><strong>持续集成：</strong>一开始，我已经提到 ce 调研，那时候形成的规格说明文档有项目每个页面的设计方式，这样 ce 的每个模块以及每个页面都已经划分好，剩下的就是开发人员对每个页面的实现。实现一个页面后进行白盒测试，一个模块的所有页面完成时进行集成测试，这符合敏捷开发的方式。</p>

<p><strong>测试驱动开发：</strong>很可惜，团队的成员（包括老成员）没有 <strong>TDD (测试驱动开发)</strong> 的经验，我们使用一个星期的时间学习，最后在讨论中决定不使用 TDD，主要原因是 TDD 讲究先写测试后开发，而我们已经进入了开发阶段；再加上没有经验，如果使用TDD很大可能会拖慢项目进度。</p>

<p><strong>每日站立会议：</strong>我们每天都会在实验室进行工作，并且在每天晚上进行一个名叫<strong>三分钟站立会议</strong>的谈论，这个会议是就是要求每个人用三分钟左右的时间回报当天的工作内容、任务目标及所遇到的问题；我们希望从这次会议<strong>获得团队中每个人的任务进度和状态，从而有效的对进度进行把控</strong>。这就符合敏捷开发的五大价值观的其中两个：<strong>沟通</strong>和<strong>反馈</strong>。</p>

<p>我清楚的记得我当初被任命开发一个叫做“生产通知单”的页面，这个页面设计上不合理，集结了很多表，关系复杂，数据量大，并且由于 Extjs 特性，导致页面加载速度慢。后来团队选择废除这个页面，上千行的代码就这样被废除了。这也符合敏捷开发的一大价值观：<strong>勇气</strong>。</p>

<p><strong>系统拥有共同的代码：</strong>我们使用 Git 对 ce 的代码进行版本管理，由于 Git 巧妙的设计，团队<strong>每个成员都用有 ce 的代码</strong>（可能是各自不同的版本），不会因为仓库的代码错误和丢失而导致项目失败。</p>

<p><strong>代码的评审和重构：</strong>由于进入第一期末尾时，发现有很多 bug ，最终讨论设立一个代码评审人员(一个师兄，他的经验比我们丰富)，他负责对代码进行评审，并将需要重构的代码标记出来形成一个新的任务，将任务授予相应的开发人员。</p>
]]></content>
  </entry>
  
</feed>
