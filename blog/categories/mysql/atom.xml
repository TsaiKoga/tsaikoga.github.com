<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mysql | TsaiKoga Blog]]></title>
  <link href="http://TsaiKoga.github.com/blog/categories/mysql/atom.xml" rel="self"/>
  <link href="http://TsaiKoga.github.com/"/>
  <updated>2018-04-30T15:37:44+08:00</updated>
  <id>http://TsaiKoga.github.com/</id>
  <author>
    <name><![CDATA[TsaiKoga]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[利用select union join 解决分页与排序的矛盾]]></title>
    <link href="http://TsaiKoga.github.com/blog/2017/10/02/li-yong-select-union-join-jie-jue-fen-ye-yu-pai-xu-de-mao-dun/"/>
    <updated>2017-10-02T18:34:00+08:00</updated>
    <id>http://TsaiKoga.github.com/blog/2017/10/02/li-yong-select-union-join-jie-jue-fen-ye-yu-pai-xu-de-mao-dun</id>
    <content type="html"><![CDATA[<p>刚入职新公司的时候，被数据库的设计吓了一跳；要在一个有缺陷的数据库上解决数据量很大而导致的查询速度慢问题。</p>

<p>首先，先来讲一下这个场景，这是一个APP的交易页面，他要显示的列表信息是衣服的款号，在这款号下面有这个款的几个SKU
（颜色尺码），以及SKU对应的销售量和交易额。</p>

<p><img src="/images/posts/2017-10-02/mysql-view.jpg" title="视图场景" alt="视图场景" /></p>

<p>然后，数据库中有三个单据表：开单OrderCreate，改单OrderModification，退货单ReturnGoods；
这三张表各有三个子表 开单子表OrderCreateGoodsSku，改单子表OrderModificationGoodsSku，退货子表ReturnGoodsSku；
这些子表都有对应的goods_count和goods_price，分别代表着交易数量和单价；</p>

<p>所以，销售量是（开单+改单-退货）的goods_count，
交易额是（开单goods_count * 开单goods_price + 改单goods_count * 改单goods_price &ndash; 退货goods_count * 退货goods_price)
当然，由于还要显示颜色尺码以及款号，我们还需要去join 有这些字段的表才行。</p>

<p>由于全部时间单据实在太多，一次性找出来构造成所需要的形式也很耗时；再者，随着时间推移，单据越来越多，这查询速度就更加不能接受了。</p>

<p>所以应该使用分页解决。但是这里还有一个需求，就是要根据交易额和销售量排序。也就是三张表查出的数据进行计算后的结果集进行排序。</p>

<p>但是这样就无法真正意义上的分页了，所以有没有办法 <strong>在排序后，取出结果集前进行分页</strong> 呢？</p>

<p>CTO建议使用视图。</p>

<h3>什么是视图</h3>

<hr />

<p>视图是一个 <strong>虚拟表</strong>，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。
但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在 <strong>引用视图时动态生成</strong>。</p>

<p>视图只是一段逻辑。</p>

<h3>使用视图解决排序与分页的矛盾</h3>

<p>现在我们只需要把三张子表的内容全部 union 成一张虚拟表就行了</p>

<p><code>sql
CREATE ALGORITHM=UNDEFINED DEFINER=`juniu`@`%` SQL SECURITY DEFINER VIEW `juniu_transfer` AS
(select `juniu_order_create_goods_sku`.`goods_id` AS `goods_id`,`juniu_order_create_goods_sku`.`goods_count` AS `goods_count`,`juniu_order_create_goods_sku`.`goods_price` AS `goods_price`,`juniu_order_create_goods_sku`.`goods_sku_id` AS `goods_sku_id`,`juniu_order_create_goods_sku`.`store_id` AS `store_id`,`juniu_order_create_goods_sku`.`customer_id` AS `customer_id`,`juniu_order_create_goods_sku`.`seller_user_id` AS `seller_user_id`,`juniu_order_create_goods_sku`.`operate_user_id` AS `operate_user_id`,`juniu_order_create_goods_sku`.`timestamp` AS `timestamp`,`juniu_order_create_goods_sku`.`transaction_id` AS `transaction_id`,`juniu_order_create_goods_sku`.`dev_flag` AS `dev_flag`,`juniu_order_create_goods_sku`.`deleted_at` AS `deleted_at`
 from `juniu_order_create_goods_sku`)
union all
(select `juniu_order_modification_goods_sku`.`goods_id` AS `goods_id`,`juniu_order_modification_goods_sku`.`goods_count_diff` AS `goods_count_diff`,`juniu_order_modification_goods_sku`.`goods_price` AS `goods_price`,`juniu_order_modification_goods_sku`.`goods_sku_id` AS `goods_sku_id`,`juniu_order_modification_goods_sku`.`store_id` AS `store_id`,`juniu_order_modification_goods_sku`.`customer_id` AS `customer_id`,`juniu_order_modification_goods_sku`.`seller_user_id` AS `seller_user_id`,`juniu_order_modification_goods_sku`.`operate_user_id` AS `operate_user_id`,`juniu_order_modification_goods_sku`.`timestamp` AS `timestamp`,`juniu_order_modification_goods_sku`.`transaction_id` AS `transaction_id`,`juniu_order_modification_goods_sku`.`dev_flag` AS `dev_flag`,`juniu_order_modification_goods_sku`.`deleted_at` AS `deleted_at`
  from `juniu_order_modification_goods_sku`)
union all
(select `juniu_return_goods_sku`.`goods_id` AS `goods_id`,(-(1) * `juniu_return_goods_sku`.`goods_count`) AS `-1*goods_count`,`juniu_return_goods_sku`.`goods_price` AS `goods_price`,`juniu_return_goods_sku`.`goods_sku_id` AS `goods_sku_id`,`juniu_return_goods_sku`.`store_id` AS `store_id`,`juniu_return_goods_sku`.`customer_id` AS `customer_id`,`juniu_return_goods_sku`.`seller_user_id` AS `seller_user_id`,`juniu_return_goods_sku`.`operate_user_id` AS `operate_user_id`,`juniu_return_goods_sku`.`timestamp` AS `timestamp`,`juniu_return_goods_sku`.`transaction_id` AS `transaction_id`,`juniu_return_goods_sku`.`dev_flag` AS `dev_flag`,`juniu_return_goods_sku`.`deleted_at` AS `deleted_at`
  from `juniu_return_goods_sku`);
</code></p>

<p>这就是创建的视图，它有了我们想要的goods_count和goods_price，并且将ReturnGoodsSku的goods_count改为了负数，这样我们可以一次性SUM起来，
实现交易额和销量的运算；</p>

<p>然后在取出所有数据之前对结果集进行排序。最后通过top或limit取出来；</p>

<p>你也可以先建立这个视图的Model，然后就可以通过ORM来获取结果集。</p>

<p>最后，说说效果，其实效果还是不能接受，因为三张表的数据 union all 后数据量太庞大，导致加载速度还是非常非常慢，union all时间实在太长了；
mysql 视图又无法使用索引；所以鱼与熊掌不可得兼。</p>

<h3>使用 select union join as 解决排序与分页的矛盾</h3>

<p>那么该怎么办呢，我是可以试图把union all的数据减少，也就是先用 where 进行筛选然后再 union all；
然后对这些已经筛选并且合并的数据进行 join 关联操作（这样可以 <strong>大大减少 join 关联的内容</strong>）；
最后再次将他们 select 出来：</p>

<p>``` sql
SELECT</p>

<pre><code>g.goods_id,
SUM(t.saleVolumn) AS saleVolumn
</code></pre>

<p>FROM</p>

<pre><code>juniu_goods AS g
</code></pre>

<p>LEFT JOIN (</p>

<pre><code>(
    SELECT
        c.goods_id AS goods_id,
        c.goods_count AS goods_count,
        c.goods_price AS goods_price,
        sum(
            c.goods_count * c.goods_price
        ) AS saleVolumn,
        c.goods_sku_id AS goods_sku_id,
        c.store_id AS store_id,
        c.customer_id AS customer_id,
        c.seller_user_id AS seller_user_id,
        c.operate_user_id AS operate_user_id,
        c. TIMESTAMP AS TIMESTAMP,
        c.transaction_id AS transaction_id,
        c.dev_flag AS dev_flag,
        c.deleted_at AS deleted_at,
        'create' AS order_type,
        0 AS return_count
    FROM
        juniu_order_create_goods_sku AS c
    WHERE
        c.store_id = 651
    GROUP BY
        goods_id
)
UNION ALL
    (
        SELECT
            m.goods_id AS goods_id,
            m.goods_count_diff AS goods_count_diff,
            m.goods_price AS goods_price,
            sum(
                m.goods_count_diff * m.goods_price
            ) AS saleVolumn,
            m.goods_sku_id AS goods_sku_id,
            m.store_id AS store_id,
            m.customer_id AS customer_id,
            m.seller_user_id AS seller_user_id,
            m.operate_user_id AS operate_user_id,
            m. TIMESTAMP AS TIMESTAMP,
            m.transaction_id AS transaction_id,
            m.dev_flag AS dev_flag,
            m.deleted_at AS deleted_at,
            'modification' AS order_type,
            0 AS return_count
        FROM
            juniu_order_modification_goods_sku AS m
        WHERE
            m.store_id = 651
        GROUP BY
            goods_id
    )
UNION ALL
    (
        SELECT
            r.goods_id AS goods_id,
            (- 1 * r.goods_count) AS goods_count,
            r.goods_price AS goods_price,
            sum(- 1 * r.goods_price) AS saleVolumn,
            r.goods_sku_id AS goods_sku_id,
            r.store_id AS store_id,
            r.customer_id AS customer_id,
            r.seller_user_id AS seller_user_id,
            r.operate_user_id AS operate_user_id,
            r. TIMESTAMP AS TIMESTAMP,
            r.transaction_id AS transaction_id,
            r.dev_flag AS dev_flag,
            r.deleted_at AS deleted_at,
            'return' AS order_type,
            r.goods_count AS return_count
        FROM
            juniu_return_goods_sku AS r
        WHERE
            r.store_id = 651
        GROUP BY
            goods_id
    )
</code></pre>

<p>) AS t ON g.goods_id = t.goods_id
WHERE</p>

<pre><code>g.store_id = 651
</code></pre>

<p>GROUP BY</p>

<pre><code>g.goods_id
</code></pre>

<p>ORDER BY</p>

<pre><code>saleVolumn DESC
</code></pre>

<p>LIMIT 0,
 20
```
这个效果拔群！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql索引]]></title>
    <link href="http://TsaiKoga.github.com/blog/2017/10/02/mysqlsuo-yin/"/>
    <updated>2017-10-02T18:05:00+08:00</updated>
    <id>http://TsaiKoga.github.com/blog/2017/10/02/mysqlsuo-yin</id>
    <content type="html"><![CDATA[<h4><a href="#1">1.索引的优缺点原因</a></h4>

<h5><a href="#1.1">1.1为什么添加索引，查询速度变快</a></h5>

<h5><a href="#1.2">1.2为什么添加上索引，速度会变慢</a></h5>

<h4><a href="#2">2.索引的类别</a></h4>

<h5><a href="#2.1">2.1主键索引</a></h5>

<h5><a href="#2.2">2.2唯一索引</a></h5>

<h5><a href="#2.3">2.3普通索引</a></h5>

<h5><a href="#2.4">2.4多列索引</a></h5>

<h5><a href="#2.5">2.5全文索引</a></h5>

<h4><a href="#3">3.加索引情况</a></h4>

<h5><a href="#3.1">3.1 关键词</a></h5>

<br/>


<p>之前一直对索引没有很清晰的认识，每次一创建表时，就给外键加索引，只知道索引提高mysql搜索效率；
前阵子查阅了很多资料，有了比较清晰的认识，现在给出如下总结：</p>

<br/>




<h2 id='1'>索引的优缺点原因</h2>


<hr />

<h3 id='1.1'>为什么添加索引，查询速度变快</h3>


<hr />

<p>计算机查找某一条记录，如果不加索引，会在整个表中一条一条比较，将匹配的记录加入 <strong>结果集</strong>，很多人说这样会很慢，加了索引就快了。</p>

<p>为什么？</p>

<p>计算机先在索引列表中找到记录的 <strong>位置</strong>，既 <strong>rowid</strong>，然后直接去表中的对应位置取出记录，我就不明白了，查找索引列表难道不需要一条一条的匹配？计算机又不会出现说，看索引列表比直接看表中的记录要快，先在索引列表中找到记录对应的rowid也是要遍历的？难道不是同样的吗？</p>

<p>原因在于 <strong>索引列表是排好序的</strong>，可以通过类似于 <strong>二分查找</strong> 快速找到。直接查找是O(n)，二分查找是log2(n)</p>

<br/>




<h3 id='1.2'>为什么添加上索引，速度会变慢</h3>


<hr />

<p>根据上面的回答，添加索引会 <strong>建立有序的索引列表</strong>，建立 <strong>索引都需要维护</strong>，你  <strong>创建、插入或删除</strong> 记录，都要到索引列表查询索引的位置并进行创建、插入或删除索引，这样非常耗时。那如果压根没去用索引，或者很少用它，这种无效索引反而会降低效率。</p>

<p>不过庆幸的是，我们目前很多主键都是使用自增 id，这样插入更新等操作都可以通过寻找到指定索引，新增叶子节点，效率挺高。</p>

<br/>


<br/>




<h2 id='2'>索引的类别</h2>


<hr />

<h3 id='2.1'>主键索引</h3>


<hr />

<p>添加PRIMARY KEY（主键索引）</p>

<p><code>sql
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )
</code></p>

<br/>


<h3 id='2.2'>唯一索引</h3>


<hr />

<p>添加UNIQUE(唯一索引)</p>

<p><code>sql
ALTER TABLE `table_name` ADD UNIQUE ( `column` )
</code></p>

<br/>


<h3 id='2.3'>普通索引</h3>


<hr />

<p>添加INDEX(普通索引)</p>

<p><code>sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column`)
</code></p>

<br/>


<h3 id='2.4'>多列索引</h3>


<hr />

<p>也叫联合索引；
添加多列索引</p>

<p><code>sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`,`column2`, `column3` )
</code>
一般用在 where 几个字段，并且使用频繁的语句；
当使用联合索引后，第一个 column1 将是一级目录，所以不用单独给它做索引，因为他已经是单独的索引了；</p>

<p>第二个 column2 是二级目录索引，所以如果你也可以增加多一个单独索引，因为不可能直接使用二级目录的；</p>

<br/>


<h3 id='2.5'>全文索引</h3>


<hr />

<p>添加FULLTEXT(全文索引)
<code>sql
ALTER TABLE `table_name` ADD FULLTEXT (`column`)
</code></p>

<h4>如何使用：</h4>

<p>在MySQL中创建全文索引之后，现在就该了解如何使用了。众所周知，在数据库中进行模糊查询是使用LIKE关键字进行查询，例如：
<code>sql
SELECT * FROM article WHERE content LIKE '%查询字符串%'
</code></p>

<p>那么，我们使用全文索引也是这样用的吗？当然不是，我们必须使用特有的语法才能使用全文索引进行查询。例如，我们想要在article表的title和content列中全文检索指定的查询字符串，可以如下编写SQL语句：</p>

<p><code>sql
SELECT * FROM article WHERE MATCH(title, content) AGAINST('查询字符串')
</code></p>

<br/>




<p><h2 id='3'>加索引的情况</h3></p>

<p><h3 id='3.1'> 关键词 </h3>
一些关键词代表可能会经常用到索引：</p>

<p><code>sql
group by
</code></p>

<p><code>sql
order by
</code></p>

<p><code>sql
select SUM()
</code></p>

<p><code>sql
select MAX()
</code></p>

<p>其实你也可以通过在可视化界面上点击排序，例如点击“created_at”，数据量很多时，点了需要等一段时间，
但是给 created_at 添加索引之后，点击排序，反应相当快。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails 利用批量操作提速]]></title>
    <link href="http://TsaiKoga.github.com/blog/2016/08/21/rails-li-yong-pi-liang-cao-zuo-ti-su/"/>
    <updated>2016-08-21T14:29:00+08:00</updated>
    <id>http://TsaiKoga.github.com/blog/2016/08/21/rails-li-yong-pi-liang-cao-zuo-ti-su</id>
    <content type="html"><![CDATA[<h4><a href="#1.1">1.1 批量查找数据</a></h4>

<h5><a href="#1.2">1.2 操作代码</a></h5>

<h4><a href="#2.1">2.1 批量插入数据</a></h4>

<h5><a href="#2.2">2.2 INFILE文件插入数据</a></h5>

<h4><a href="#3.1">3.1 批量更改schema数据库</a></h4>

<h2 id="1.1">1.1 批量查找数据</h2>


<hr />

<p>由于之前一直在做后台的数据，其中有个任务是关于 财务库存 的页面.</p>

<blockquote><p>这个“财务库存”有产品和日期选项，您可以通过选择产品，查看它在某段时间内的库存价格等情况。</p>

<p>将采购入库单数据[PurchaseOrderBill]，销售出库单数据[OutStorageOrder]，异常取货和仓库调整单数据整合在一个页面；
根据日期排序来显示这个页面的内容，以及这些内容的成本价格变化，这里的价格根据这些取出来的数据进行排列后再进行运算得出。</p>

<p>项目中有近5w条产品记录，又要将“采购入库单”和“销售出库单”与 产品product进行关联查找，耗时挺大的。</p>

<p>这时候公司那边说要提供一次性下载所有产品的财务库存数据，不过不需要显示价格变化情况，直接显示最后一条价格结果就行了。</p></blockquote>

<p>近5w条的 product 产品关联(joins/includes)的单据进行计算价格，然后显示结果。
如何加快查找速度呢？</p>

<p>答案是进行 <strong>批量</strong> 查找。</p>

<h3 id="1.2">1.2 操作代码</h3>


<p>用代码说明吧，首先当然对于这么庞大的数据量，要进行 <strong>分页</strong> 处理：
``` ru</p>

<pre><code>per_page = 100
page = 0
total_page = (Product.count.to_f / per_page).ceil
</code></pre>

<p>```</p>

<p>每一页进行 <strong>批量</strong> 操作：
``` ru</p>

<pre><code>total_page.times do
  products = Product.limit(per_page).offset(page * per_page)
  bill_items = bill_inventory_valuation_details products        # 符合条件的采购入库单数据，此方法的查找也必须对 products 进行批量查找
  sell_items = sell_inventory_valuation_details products        # 符合条件的销售出库数据
  package_items = package_inventory_valuation_details products  # 异常出库数据
  adjust = adjust_inventory_valuation_details products          # 调整仓库数据
  products.each do |product|
    datas = []
    datas += bill_items[product.id].map{|item| {id: item.id, quantity: item.quantity, price: item.price}}
    # 对查出的数据进行处理，构造最终结果
    ... ...
  end
end
</code></pre>

<p>```</p>

<p>批量的产品分别进行采购单Bill,销售单Sell，包裹Package，还有调整库存单据Adjust的查询然后全部group_by产品ID，
最后将以产品ID来循环，将这个产品的所有单据组合一起，然后就可以算它的库存销售情况。
<strong>记住：代码循环永远比循环数据库操作要快的多</strong></p>

<p>``` ru
def bill_inventory_valuation_details products</p>

<pre><code>bill_items = PurchaseOrderBillItem.joins(:purchase_order_bill =&gt; :purchase_order).
                                   includes(:purchase_order_bill =&gt; :purchase_order).
                                   where("purchase_order_bills.status = ?", PurchaseOrderBill::STATUS[:finished]).
                                   where("purchase_order_bills.date BETWEEN ? AND ?", @start_date, @end_date).
                                   where("purchase_order_bill_items.product_id IN (?)", products.pluck(:id)).
                                   group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def sell_inventory_valuation_details products</p>

<pre><code>sell_items = OutStorageOrderItem.joins(:out_storage_order).
                                 includes(:out_storage_order).
                                 where("out_storage_orders.out_storage_order_type = ?", 3).
                                 where("out_storage_orders.created_at BETWEEN ? AND ?", @start_date.beginning_of_day, @end_date.end_of_day).
                                 where("out_storage_orders.package_id IS NOT NULL OR out_storage_orders.package_group_id IS NOT NULL").
                                 where("out_storage_order_items.product_id IN (?)", products.pluck(:id)).
                                 group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def adjust_inventory_valuation_details products</p>

<pre><code>adjust = AdjustInventoryRecord.where("the_date BETWEEN ? AND ?", @start_date, @end_date).where(product_id: products.pluck(:id)).group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def package_inventory_valuation_details products</p>

<pre><code>package_items = PackageItem.eager_load(:package).where(product_id: products.pluck(:id)).
                                              where("packages.state = ?", Package::STATE_VALUES[:processed]).
                                              where("packages.dropship = ?", false).
                                              where("packages.shipped_at &gt;= ? AND packages.shipped_at &lt;= ?", @start_date, @end_date).group_by(&amp;:product_id)
</code></pre>

<p>  end
```</p>

<p>这样原先没有进行批量操作会耗时接近12个小时，使用了批量操作后仅为2个多小时。</p>

<h2 id="2.1">2.1 批量插入数据</h2>


<hr />

<p>当你要对大量数据进行插入数据库的操作时，一条条插入将是及其愚蠢的行为。如何进行批量插入呢？</p>

<p>可以先看看这篇文章：<a href="https://www.coffeepowered.net/2009/01/23/mass-inserting-data-in-rails-without-killing-your-performance/">Mass inserting data in Rails without killing your performance</a></p>

<p>这篇文章提到 Rails 快速插入数据的四种方法：</p>

<ol>
<li><p>Use transactions</p></li>
<li><p>Get down and dirty with the raw SQL</p></li>
<li><p>A single mass insert</p></li>
<li><p>Use INSERT statements with multiple VALUES lists with ar-extensions OR activerecord-import</p></li>
</ol>


<p>第四种方式是AR方式的70倍左右，而公司后台使用的正是 activerecord-import,
做法很简单，先将数据创建 <strong>存于内存</strong>，然后批量 import <strong>插入</strong> 数据库：</p>

<p>``` ru</p>

<pre><code>(controller.action_methods.to_a - excepts).each do |action|
  need_imports &lt;&lt; Permission.new(subject: subject, action: action, description: "#{action.humanize} of #{subject}")
end
Permission.import need_imports
</code></pre>

<p>```</p>

<p>这样已经很快了，还有更快的吗？</p>

<h3 id="2.2">2.2 INFILE文件插入数据 </h3>


<p>From MySQL Doc:</p>

<blockquote><p>When loading a table from a text file, use LOAD DATA INFILE. This is usually 20 times faster than using INSERT statements</p></blockquote>

<p>SQL语句：</p>

<p><code>
(15955.1ms)  LOAD DATA LOCAL INFILE '/Users/tsaikoga/out_storage_orders.txt'
REPLACE INTO TABLE out_storage_orders FIELDS TERMINATED BY ',' (`id`,`warehouse_id`,`destination_id`,`user_id`,`out_storage_order_type`,`out_storage_reason_type`,`status`,`quantity`,`package_id`)
</code></p>

<p>插入行数：</p>

<p>``` sh</p>

<pre><code>wc -l &lt; /Users/tsaikoga/out_storage_orders.txt
100000
</code></pre>

<p>```</p>

<h3 id="3.1">3.1 批量更改schema数据库</h3>


<hr />

<p>你有没有发现，当你某张表的数据非常非常多的时候，你想要更改其中一个字段的类型，然后执行 migrate ；
执行时间非常长，你厌倦了等待，只好 ctrl+c 撤销了migrate，但是实际上数据库中的记录已经有很大一部分改变了字段的类型。
这时候你想再migrate，会出现这种类型的字段已存在的提示。（当然你可以利用mysql的界面工具或直接到mysql更改字段类型进行拯救）</p>

<p>这里提供一个 Rails 的方法，将数据大批量进行更改。
比方说，以下是一段更改 orders 表的 shipping_first_name shipping_last_name 名称的方法：</p>

<pre><code>rename_column :orders, "shipping_first_name", "origin_shipping_first_name"
rename_column :orders, "shipping_last_name", "origin_shipping_last_name"
</code></pre>

<p>执行migrate用时非常长，还不如使用如下代码：</p>

<p>``` ru</p>

<pre><code>class RenameOldOrderAddressRelatedColumn &lt; ActiveRecord::Migration
  def up
    change_table(:orders, :bulk =&gt; true) do |t|
      t.rename :order_status_code_id, :state
      t.remove :in_process
      [:first_name,
       :last_name,
       :country,
       :state].each do |column|
        t.rename "shipping_#{column}", "origin_shipping_#{column}"
      end
    end
  end
end
</code></pre>

<p>```</p>

<p>以上代码只生成一句 SQL 语句，数据库迁移时间大大减少。</p>

<p>```</p>

<pre><code>ALTER TABLE `orders` DROP `in_process`, CHANGE `shipping_first_name` `origin_shipping_first_name` varchar(50) DEFAULT NULL, CHANGE `shipping_last_name` `origin_shipping_last_name` varchar(50) DEFAULT NULL, CHANGE `shipping_country` `origin_shipping_country` varchar(255) DEFAULT NULL, CHANGE `shipping_state` `origin_shipping_state` varchar(255) DEFAULT NULL...
</code></pre>

<p>```</p>

<p>相关文档：</p>

<p><a href="http://dev.mysql.com/doc/refman/5.5/en/load-data.html">http://dev.mysql.com/doc/refman/5.5/en/load-data.html</a>
<a href="http://dev.mysql.com/doc/refman/5.5/en/insert-speed.html">http://dev.mysql.com/doc/refman/5.5/en/insert-speed.html</a></p>

<p>总结，对于大数据一定要进行批量处理。</p>
]]></content>
  </entry>
  
</feed>
