<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mysql | TsaiKoga Blog]]></title>
  <link href="http://TsaiKoga.github.com/blog/categories/mysql/atom.xml" rel="self"/>
  <link href="http://TsaiKoga.github.com/"/>
  <updated>2017-05-31T12:17:44+08:00</updated>
  <id>http://TsaiKoga.github.com/</id>
  <author>
    <name><![CDATA[TsaiKoga]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rails 利用批量操作提速]]></title>
    <link href="http://TsaiKoga.github.com/blog/2016/08/21/rails-li-yong-pi-liang-cao-zuo-ti-su/"/>
    <updated>2016-08-21T14:29:00+08:00</updated>
    <id>http://TsaiKoga.github.com/blog/2016/08/21/rails-li-yong-pi-liang-cao-zuo-ti-su</id>
    <content type="html"><![CDATA[<h4><a href="#1.1">1.1 批量查找数据</a></h4>

<h5><a href="#1.2">1.2 操作代码</a></h5>

<h4><a href="#2.1">2.1 批量插入数据</a></h4>

<h5><a href="#2.2">2.2 INFILE文件插入数据</a></h5>

<h4><a href="#3.1">3.1 批量更改schema数据库</a></h4>

<h2 id="1.1">1.1 批量查找数据</h2>


<hr />

<p>由于之前一直在做后台的数据，其中有个任务是关于 财务库存 的页面.</p>

<blockquote><p>这个“财务库存”有产品和日期选项，您可以通过选择产品，查看它在某段时间内的库存价格等情况。</p>

<p>将采购入库单数据[PurchaseOrderBill]，销售出库单数据[OutStorageOrder]，异常取货和仓库调整单数据整合在一个页面；
根据日期排序来显示这个页面的内容，以及这些内容的成本价格变化，这里的价格根据这些取出来的数据进行排列后再进行运算得出。</p>

<p>项目中有近5w条产品记录，又要将“采购入库单”和“销售出库单”与 产品product进行关联查找，耗时挺大的。</p>

<p>这时候公司那边说要提供一次性下载所有产品的财务库存数据，不过不需要显示价格变化情况，直接显示最后一条价格结果就行了。</p></blockquote>

<p>近5w条的 product 产品关联(joins/includes)的单据进行计算价格，然后显示结果。
如何加快查找速度呢？</p>

<p>答案是进行 <strong>批量</strong> 查找。</p>

<h3 id="1.2">1.2 操作代码</h3>


<p>用代码说明吧，首先当然对于这么庞大的数据量，要进行 <strong>分页</strong> 处理：
``` ru</p>

<pre><code>per_page = 100
page = 0
total_page = (Product.count.to_f / per_page).ceil
</code></pre>

<p>```</p>

<p>每一页进行 <strong>批量</strong> 操作：
``` ru</p>

<pre><code>total_page.times do
  products = Product.limit(per_page).offset(page * per_page)
  bill_items = bill_inventory_valuation_details products        # 符合条件的采购入库单数据，此方法的查找也必须对 products 进行批量查找
  sell_items = sell_inventory_valuation_details products        # 符合条件的销售出库数据
  package_items = package_inventory_valuation_details products  # 异常出库数据
  adjust = adjust_inventory_valuation_details products          # 调整仓库数据
  products.each do |product|
    datas = []
    datas += bill_items[product.id].map{|item| {id: item.id, quantity: item.quantity, price: item.price}}
    # 对查出的数据进行处理，构造最终结果
    ... ...
  end
end
</code></pre>

<p>```</p>

<p>批量的产品分别进行采购单Bill,销售单Sell，包裹Package，还有调整库存单据Adjust的查询然后全部group_by产品ID，
最后将以产品ID来循环，将这个产品的所有单据组合一起，然后就可以算它的库存销售情况。
<strong>记住：代码循环永远比循环数据库操作要快的多</strong></p>

<p>``` ru
def bill_inventory_valuation_details products</p>

<pre><code>bill_items = PurchaseOrderBillItem.joins(:purchase_order_bill =&gt; :purchase_order).
                                   includes(:purchase_order_bill =&gt; :purchase_order).
                                   where("purchase_order_bills.status = ?", PurchaseOrderBill::STATUS[:finished]).
                                   where("purchase_order_bills.date BETWEEN ? AND ?", @start_date, @end_date).
                                   where("purchase_order_bill_items.product_id IN (?)", products.pluck(:id)).
                                   group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def sell_inventory_valuation_details products</p>

<pre><code>sell_items = OutStorageOrderItem.joins(:out_storage_order).
                                 includes(:out_storage_order).
                                 where("out_storage_orders.out_storage_order_type = ?", 3).
                                 where("out_storage_orders.created_at BETWEEN ? AND ?", @start_date.beginning_of_day, @end_date.end_of_day).
                                 where("out_storage_orders.package_id IS NOT NULL OR out_storage_orders.package_group_id IS NOT NULL").
                                 where("out_storage_order_items.product_id IN (?)", products.pluck(:id)).
                                 group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def adjust_inventory_valuation_details products</p>

<pre><code>adjust = AdjustInventoryRecord.where("the_date BETWEEN ? AND ?", @start_date, @end_date).where(product_id: products.pluck(:id)).group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def package_inventory_valuation_details products</p>

<pre><code>package_items = PackageItem.eager_load(:package).where(product_id: products.pluck(:id)).
                                              where("packages.state = ?", Package::STATE_VALUES[:processed]).
                                              where("packages.dropship = ?", false).
                                              where("packages.shipped_at &gt;= ? AND packages.shipped_at &lt;= ?", @start_date, @end_date).group_by(&amp;:product_id)
</code></pre>

<p>  end
```</p>

<p>这样原先没有进行批量操作会耗时接近12个小时，使用了批量操作后仅为2个多小时。</p>

<h2 id="2.1">2.1 批量插入数据</h2>


<hr />

<p>当你要对大量数据进行插入数据库的操作时，一条条插入将是及其愚蠢的行为。如何进行批量插入呢？</p>

<p>可以先看看这篇文章：<a href="https://www.coffeepowered.net/2009/01/23/mass-inserting-data-in-rails-without-killing-your-performance/">Mass inserting data in Rails without killing your performance</a></p>

<p>这篇文章提到 Rails 快速插入数据的四种方法：</p>

<ol>
<li><p>Use transactions</p></li>
<li><p>Get down and dirty with the raw SQL</p></li>
<li><p>A single mass insert</p></li>
<li><p>Use INSERT statements with multiple VALUES lists with ar-extensions OR activerecord-import</p></li>
</ol>


<p>第四种方式是AR方式的70倍左右，而公司后台使用的正是 activerecord-import,
做法很简单，先将数据创建 <strong>存于内存</strong>，然后批量 import <strong>插入</strong> 数据库：</p>

<p>``` ru</p>

<pre><code>(controller.action_methods.to_a - excepts).each do |action|
  need_imports &lt;&lt; Permission.new(subject: subject, action: action, description: "#{action.humanize} of #{subject}")
end
Permission.import need_imports
</code></pre>

<p>```</p>

<p>这样已经很快了，还有更快的吗？</p>

<h3 id="2.2">2.2 INFILE文件插入数据 </h3>


<p>From MySQL Doc:</p>

<blockquote><p>When loading a table from a text file, use LOAD DATA INFILE. This is usually 20 times faster than using INSERT statements</p></blockquote>

<p>SQL语句：</p>

<p><code>
(15955.1ms)  LOAD DATA LOCAL INFILE '/Users/tsaikoga/out_storage_orders.txt'
REPLACE INTO TABLE out_storage_orders FIELDS TERMINATED BY ',' (`id`,`warehouse_id`,`destination_id`,`user_id`,`out_storage_order_type`,`out_storage_reason_type`,`status`,`quantity`,`package_id`)
</code></p>

<p>插入行数：</p>

<p>``` sh</p>

<pre><code>wc -l &lt; /Users/tsaikoga/out_storage_orders.txt
100000
</code></pre>

<p>```</p>

<h3 id="3.1">3.1 批量更改schema数据库</h3>


<hr />

<p>你有没有发现，当你某张表的数据非常非常多的时候，你想要更改其中一个字段的类型，然后执行 migrate ；
执行时间非常长，你厌倦了等待，只好 ctrl+c 撤销了migrate，但是实际上数据库中的记录已经有很大一部分改变了字段的类型。
这时候你想再migrate，会出现这种类型的字段已存在的提示。（当然你可以利用mysql的界面工具或直接到mysql更改字段类型进行拯救）</p>

<p>这里提供一个 Rails 的方法，将数据大批量进行更改。
比方说，以下是一段更改 orders 表的 shipping_first_name shipping_last_name 名称的方法：</p>

<pre><code>rename_column :orders, "shipping_first_name", "origin_shipping_first_name"
rename_column :orders, "shipping_last_name", "origin_shipping_last_name"
</code></pre>

<p>执行migrate用时非常长，还不如使用如下代码：</p>

<p>``` ru</p>

<pre><code>class RenameOldOrderAddressRelatedColumn &lt; ActiveRecord::Migration
  def up
    change_table(:orders, :bulk =&gt; true) do |t|
      t.rename :order_status_code_id, :state
      t.remove :in_process
      [:first_name,
       :last_name,
       :country,
       :state].each do |column|
        t.rename "shipping_#{column}", "origin_shipping_#{column}"
      end
    end
  end
end
</code></pre>

<p>```</p>

<p>以上代码只生成一句 SQL 语句，数据库迁移时间大大减少。</p>

<p>```</p>

<pre><code>ALTER TABLE `orders` DROP `in_process`, CHANGE `shipping_first_name` `origin_shipping_first_name` varchar(50) DEFAULT NULL, CHANGE `shipping_last_name` `origin_shipping_last_name` varchar(50) DEFAULT NULL, CHANGE `shipping_country` `origin_shipping_country` varchar(255) DEFAULT NULL, CHANGE `shipping_state` `origin_shipping_state` varchar(255) DEFAULT NULL...
</code></pre>

<p>```</p>

<p>相关文档：</p>

<p><a href="http://dev.mysql.com/doc/refman/5.5/en/load-data.html">http://dev.mysql.com/doc/refman/5.5/en/load-data.html</a>
<a href="http://dev.mysql.com/doc/refman/5.5/en/insert-speed.html">http://dev.mysql.com/doc/refman/5.5/en/insert-speed.html</a></p>

<p>总结，对于大数据一定要进行批量处理。</p>
]]></content>
  </entry>
  
</feed>
