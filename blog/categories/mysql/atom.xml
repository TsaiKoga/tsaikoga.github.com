<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mysql | TsaiKoga Blog]]></title>
  <link href="https://TsaiKoga.github.com/blog/categories/mysql/atom.xml" rel="self"/>
  <link href="https://TsaiKoga.github.com/"/>
  <updated>2019-05-11T16:04:40+08:00</updated>
  <id>https://TsaiKoga.github.com/</id>
  <author>
    <name><![CDATA[TsaiKoga]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Laravel 的数据库事务源码分析]]></title>
    <link href="https://TsaiKoga.github.com/blog/2019/05/09/laravel-de-shu-ju-ku-shi-wu-yuan-ma-fen-xi/"/>
    <updated>2019-05-09T17:54:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2019/05/09/laravel-de-shu-ju-ku-shi-wu-yuan-ma-fen-xi</id>
    <content type="html"><![CDATA[<p>在批发档口记账 app 中，由于用户数量越来越多，有几个老客户了反馈单据丢失的问题；</p>

<p><strong>打个比方：</strong></p>

<p>我们开单会去创建开单表 <code>order_create</code>，开单表会生成详情 <code>order_create_goods_sku</code>，然后生成欠货表 <code>order_owe_goods_sku</code>；</p>

<p>然后接着是发货请求，会生成发货主表 <code>order_delivery</code> 和 发货详情 <code>order_delivery_goods_sku</code>；发货会生成库存变动记录；</p>

<br>


<p>这时候已经有了开单和开单详情，证明已经开单请求成功；</p>

<p>但是库存变动记录有，发货单却找不到；这时候我去查找了日志，发现也有发货请求；
然而通过库存变动记录找不到相应的发货单了，这是怎么回事，难道是被人撤销了吗？</p>

<br>


<p>全局查找了整个项目，没有强删除的接口，难道是代码有问题？</p>

<p>那么我开始定位代码，因为事务包裹着整个"发货的创建流程" 和 &ldquo;库存变动记录的生成"；
所以要么就全部回滚，那么不太可能是回滚问题？</p>

<br>


<h1>跟踪数据库操作：</h1>

<hr />

<p>那是不是有人从数据库删除了？</p>

<p>我写了个触发器，只要有人强删记录就会记录到一张跟踪表：</p>

<p>1.首先创建跟踪表：
<code>sql
CREATE TABLE `juniu_track_delivery` (
  `track_delivery_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '订单ID',
  `order_delivery_id` int(11) NOT NULL DEFAULT 0 COMMENT  '发货单ID',
  `order_id` int(11) NOT NULL DEFAULT 0 COMMENT '订单ID',
  `deliver_timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '发货时间',
  `deleted_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '被删除时间',
  `deleted_by` varchar(50) DEFAULT '' COMMENT '删除的用户ip',
  PRIMARY KEY (`track_delivery_id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8;
</code></p>

<br>


<p>2.建立触发器 <code>track_delete_delivery</code> 跟踪：
``` sql
DELIMITER //
CREATE TRIGGER track_delete_delivery
AFTER DELETE
   ON juniu_order_delivery FOR EACH ROW
BEGIN
   DECLARE vUser varchar(50);
   &mdash; Find username of person performing the DELETE into table
   SELECT USER() INTO vUser;
   &mdash; Insert record into audit table
   INSERT INTO juniu_track_delivery
   ( order_delivery_id,</p>

<pre><code> order_id,
 deliver_timestamp,
 deleted_at,
 deleted_by)
</code></pre>

<p>   VALUES
   ( OLD.order_delivery_id,</p>

<pre><code> OLD.order_id,
 OLD.deliver_timestamp,
 SYSDATE(),
 vUser );
</code></pre>

<p>END; //
DELIMITER ;
```
观察一段时间，仍有数据丢失，但是并没有跟踪到，初步判断不是人为删除；</p>

<br>


<h1>Mysql 事务特性：</h1>

<hr />

<p>Mysql 事务具有四大特性：A（原子性）C（一致性）I（隔离性）D（持久性）；</p>

<p>事务有五个级别：</p>

<blockquote><ol>
<li><p>TRANSACTION_NONE  不使用事务。</p></li>
<li><p>TRANSACTION_READ_UNCOMMITTED  未提交读，允许脏读。</p></li>
<li><p>TRANSACTION_READ_COMMITTED  提交读，防止脏读，最常用的隔离级别,并且是大多数数据库的默认隔离级别</p></li>
<li><p>TRANSACTION_REPEATABLE_READ  重复读，可以防止脏读和不可重复读，</p></li>
<li><p>TRANSACTION_SERIALIZABLE  序列化，可以防止脏读，不可重复读取和幻读，（事务串行化）会降低数据库的效率</p></li>
</ol>
</blockquote>

<p>1、<strong>脏读：</strong> 事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据</p>

<p>2、<strong>不可重复读：</strong> 事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。</p>

<p>3、<strong>幻读：</strong> 事务 A 修改了表中所有数据，但是事务 B 插入了一条数据，当事务 A 查询数据发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</p>

<p><strong>小结：</strong> 不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表</p>

<br>


<p>最后我们来查看一下 Mysql 数据库事务配置，看是不是事务配置错误：</p>

<p>``` sql
select @@tx_isolation;</p>

<p>select @@session.tx_isolation;</p>

<p>select @@global.tx_isolation;
```</p>

<p>显示结果都是 <code>READ-COMMITTED</code></p>

<br>


<h1>查看事务源码：</h1>

<hr />

<p>重新回到回滚代码，既然都被包裹起来，但是又回滚不成功，我开始查阅 Laravel API，因为我怕会是框架有问题，</p>

<p>找到相应的 laravel 版本 5.1: <a href="https://laravel.com/api/5.1/">https://laravel.com/api/5.1/</a></p>

<p>寻找 <code>transaction</code>，显示有</p>

<blockquote><p>Illuminate\Database\ConnectionInterface::transaction</p>

<p>Illuminate\Database\Connection::transaction</p></blockquote>

<p>接口定义的是规则，所以我看数据库的连接类 <code>Illuminate\Database\Connection::transaction</code></p>

<p>这里有几个我们要看的方法：
``` php
mixed transaction(Closure $callback)</p>

<p>void beginTransaction()</p>

<p>void commit()</p>

<p>void rollBack()
```
点击右边行号，可以跳转到 5.1 源代码文件：</p>

<p>先查看 <code>transaction</code> 方法，此处参数是一个闭包，我们项目中使用的不是这种写法：
```php</p>

<pre><code>public function transaction(Closure $callback)
{
    $this-&gt;beginTransaction();
    // We'll simply execute the given callback within a try / catch block
    // and if we catch any exception we can rollback the transaction
    // so that none of the changes are persisted to the database.
    try {
        $result = $callback($this);
        $this-&gt;commit();
    }
    // If we catch an exception, we will roll back so nothing gets messed
    // up in the database. Then we'll re-throw the exception so it can
    // be handled how the developer sees fit for their applications.
    catch (Exception $e) {
        $this-&gt;rollBack();
        throw $e;
    } catch (Throwable $e) {
        $this-&gt;rollBack();
        throw $e;
    }
    return $result;
}
</code></pre>

<p><code>
整个事务用</code>try catch<code>包裹住，如果失败，直接抛出异常，并且回滚，</code>transactions``` 自然减为 0；</p>

<p>然后我看看我们项目中所使用的方法，通过<code>DB::beginTransaction();</code>
开始，然后中途出错，直接写 <code>DB::rollback()</code> ，
然后 <code>return</code> 返回，最后成功提交 <code>DB::commit()</code>。</p>

<p>先看看 <code>beginTransaction()</code> 的源码:
``` php</p>

<pre><code>public function beginTransaction()
{
    if ($this-&gt;transactions == 0) {
        try {
            $this-&gt;pdo-&gt;beginTransaction();
        } catch (Exception $e) {
            if ($this-&gt;causedByLostConnection($e)) {
                $this-&gt;reconnect();
                $this-&gt;pdo-&gt;beginTransaction();
            } else {
                throw $e;
            }
        }
    } elseif ($this-&gt;transactions &gt;= 1 &amp;&amp; $this-&gt;queryGrammar-&gt;supportsSavepoints()) {
        $this-&gt;pdo-&gt;exec(
            $this-&gt;queryGrammar-&gt;compileSavepoint('trans'.($this-&gt;transactions + 1))
        );
    }
    $this-&gt;transactions++;
    $this-&gt;fireConnectionEvent('beganTransaction');
}
</code></pre>

<p>```</p>

<p>可以看到，这里的 <code>transactions</code> 属性记录多少层事务，通过 <code>try catch</code> 包裹一个事务开始，如果失败，重新尝试连接，并将<code>transaction + 1</code>；</p>

<br>


<p>再看 <code>rollback()</code>
``` php</p>

<pre><code>public function rollBack()
{
    if ($this-&gt;transactions == 1) {
        $this-&gt;pdo-&gt;rollBack();
    } elseif ($this-&gt;transactions &gt; 1 &amp;&amp; $this-&gt;queryGrammar-&gt;supportsSavepoints()) {
        $this-&gt;pdo-&gt;exec(
            $this-&gt;queryGrammar-&gt;compileSavepointRollBack('trans'.$this-&gt;transactions)
        );
    }
    $this-&gt;transactions = max(0, $this-&gt;transactions - 1);
    $this-&gt;fireConnectionEvent('rollingBack');
}
</code></pre>

<p>```
这里 <strong>只有在 transactions 为 1 的时候，才去 rollback 整个事务</strong>；</p>

<br>


<p>再来看看 <code>commit()</code></p>

<p>``` php</p>

<pre><code>public function commit()
{
    if ($this-&gt;transactions == 1) {
        $this-&gt;pdo-&gt;commit();
    }
    $this-&gt;transactions--;
    $this-&gt;fireConnectionEvent('committed');
}
</code></pre>

<p><code>
也是只有当</code>transactions == 1<code>的时候才会</code>commit``` 整个事务；</p>

<p>不像 <code>transaction</code> 闭包那样，有整个 <code>try catch</code> 包裹，这里每一个步骤都要自己控制，</p>

<p>项目中事务的写法经常是：
``` php
DB::beginTransaction();</p>

<p>$res = OrderDelivery::insert([&hellip;]);
if (!$res) {</p>

<pre><code>DB::rollback();
return $this-&gt;fail(-1, '创建失败');
</code></pre>

<p>}
$delivery_skus = json_decode($color_size_matrix, true);
OrderDeliveryGoodsSku::insert($delivery_skus);
&hellip;
&hellip;
DB::commit();</p>

<p>```</p>

<p>那么就有问题了，如果某个步骤出错，但是因为没有抛出异常，因为查看 API 像 <code>insert</code> 失败会返回 <code>false</code>；</p>

<p>需要人工判断返回值去 <code>rollback</code>，如果没有判断，也没有 <code>rollback</code>，这样 <code>transactions</code> 就没有减到 1；
这就有可能跑到 <code>commit</code> 那里去给 <code>transactions - 1</code> 了；</p>

<h1>结论：</h1>

<hr />

<p>所以较好的方法还是，</p>

<ol>
<li><code>transaction</code> 带闭包参数；</li>
<li><code>beginTransaction + try catch</code></li>
</ol>


<p>用 <code>beginTransaction + try catch</code>，只要有问题，直接到 <code>catch</code> 那做一次回滚即可，不用担心哪里忘了 <code>rollback</code>；</p>

<p>示例：
``` php
DB::beginTrasaction();
try {</p>

<pre><code>OrderModificationGoodsSku::insertGetId();
OrderOweGoodsSku::where()-&gt;update();
DB::commit();
</code></pre>

<p>} catch (\Throwable $e) {
    // For php 7</p>

<pre><code>DB::rollback();
//throw $e;
Log::error($e-&gt;getMessage());
return $this-&gt;fail(-1, "创建失败");
</code></pre>

<p>} catch(\Exception $e) {</p>

<pre><code>// For php5
DB::rollback();
//throw $e;
Log::error($e-&gt;getMessage());
return $this-&gt;fail(-1, "创建失败");
</code></pre>

<p>}</p>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用 Mysql 日志及插件进行性能优化]]></title>
    <link href="https://TsaiKoga.github.com/blog/2018/05/12/li-yong-mysql-ri-zhi-ji-cha-jian-jin-xing-xing-neng-you-hua/"/>
    <updated>2018-05-12T17:37:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2018/05/12/li-yong-mysql-ri-zhi-ji-cha-jian-jin-xing-xing-neng-you-hua</id>
    <content type="html"><![CDATA[<h4><a href="#1">1. 数据库优化的目的</a></h4>

<h4><a href="#2">2. SQL及索引优化</a></h4>

<h5><a href="#2.1">一、慢查询日志设置</a></h5>

<h5><a href="#2.2">二、慢查询日志的分析工具</a></h5>

<h6><a href="#2.2.1">2.1 如何通过慢查询日志发现有问题的SQL</a></h6>

<h6><a href="#2.2.2">2.2 如何分析SQL查询</a></h6>

<h5><a href="#2.2">三、建立索引</a></h5>

<h6><a href="#2.3.1">3.1 如何选择合适的列建立索引：</a></h6>

<h6><a href="#2.3.2">3.2 索引的维护和优化—重复及冗余索引</a></h6>

<h6><a href="#2.3.3">3.3 删除不用索引</a></h6>

<h5><a href="#2.4">四、系统配置优化</a></h5>

<h4><a href="#3">3. 硬件要求</a></h4>

<h1 id='1'>数据库优化的目的：</h1>


<hr />

<h4>避免出现页面访问错误</h4>

<ul>
<li>由于数据库连接timeout产生页面5xx错误</li>
<li>由于慢查询造成页面无法加载</li>
<li>由于阻塞（加锁）造成数据无法提交</li>
</ul>


<br/>


<h4>增加数据库稳定性</h4>

<ul>
<li>很多数据库查询都是由低效的查询引起的</li>
</ul>


<br/>


<h4>优化用户体验</h4>

<ul>
<li>流畅页面访问速度</li>
<li>良好的网站功能体验</li>
</ul>


<br/>


<p><img src="/images/posts/2018-05-12/mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%87%91%E5%AD%97%E5%A1%94.gif" title="mysql性能优化金字塔" alt="mysql性能优化金字塔" /></p>

<br/>


<br/>




<h1 id='2'>SQL及索引优化</h1>


<hr />

<h3>如何发现有问题的SQL？</h3>

<br/>




<h2 id='2.1'>一、慢查询日志设置</h2>


<hr />

<p>使用 Mysql 慢查日志对有效率问题的 SQL 进行监控</p>

<p>``` sql</p>

<h1>首先进入 mysql 的cli</h1>

<p>show variables like &ldquo;slow_query_log&rdquo;
```</p>

<p><img src="/images/posts/2018-05-12/mysql_query_log.gif" title="mysql query log" alt="mysql query log" /></p>

<p><code>sql
set global slow_query_log_file='/home/mysql/sql_log/mysql_slow.log' # 设置慢查询日志存储路径
set global log_queries_now_using_indexes=on;                        # 将没有索引的慢查询加入到慢查询日志中
set global long_query_time=1                                        # 将大于1s的设置到慢查询日志中
Set global slow_query_log=on;                                       # 开启慢查询日志记录
</code></p>

<h3>慢查询日志所包含的内容</h3>

<blockquote><p>执行 SQL 的主机信息</p>

<p>User@Host:root[root] @ localhost []</p>

<p>SQL的执行信息</p>

<p>Query_time: 0.000024 Lock_time: 0.0000 Rows_sent: 0  Rows_examined: 0</p>

<p>SQL执行时间</p>

<p>SET timestamp=1402389328</p>

<p>SQL的内容</p>

<p>select CONCAT(’storage engine:’,  @@storage_engine) as INFO;</p></blockquote>

<br/>


<br/>




<h2 id='2.2'>二、慢查询日志的分析工具：</h2>


<hr />

<h4>mysqldumpslow</h4>

<p><strong>mysqldumpslow</strong> [OPTS…] [LOGS…]    官方分析工具
返回count为查询次数，time为查询时间 ，rows为查询返回行数</p>

<p><img src="/images/posts/2018-05-12/mysqldumpslow.gif" alt="mysql dump slow" /></p>

<br/>


<h4>pt-query-digest</h4>

<p>输出到文件：</p>

<p><code>sql
pt-query-digest slow-log &gt; slow_log.report
</code></p>

<p>输出到数据库表：</p>

<p><code>sql
pt-query-digest slow.log -review h=127.0.0.1, D=test, p=root, P=3306, u=root, t=query_review --create-reviewtable --review-history t=hostname_slow
</code></p>

<p><img src="/images/posts/2018-05-12/pt-query-digest.gif" title="pt-query-digest" alt="pt-query-digest" />
<img src="/images/posts/2018-05-12/pt-query-digest2.gif" title="pt-query-digest" alt="pt-query-digest" /></p>

<br/>


<br/>




<h2 id='2.2.1'>如何通过慢查询日志发现有问题的SQL</h2>


<hr />

<h4>1.查询次数多且每次查询占用时间长的SQL</h4>

<p>通常为 pt-query-digest 分析的前几个查询</p>

<h4>2.IO大的SQL</h4>

<p>注意 pt-query-digest 分析中的 Rows examine 项【扫描行数越多，IO越大】</p>

<h4>3.未命中索引的SQL</h4>

<p>注意 pt-query-digest 分析中Rows examines 和 Rows Send 的对比 【如果扫描行数 远大于 发送行数，要么没有索引，要么索引无效，导致类似于全表扫描】</p>

<p><img src="/images/posts/2018-05-12/pt-query-digest3.gif" title="pt-query-digest" alt="pt-query-digest" /></p>

<br/>


<br/>




<h2 id='2.2.2'>如何分析SQL查询：</h2>


<hr />

<p>使用 explain 查询 SQL 的执行计划</p>

<p><img src="/images/posts/2018-05-12/explain.gif" title="explain" alt="explain" /></p>

<p>table：                显示这一行数据属于哪张表</p>

<p>type：                 重要的列，显示连接使用了何种类型。从最好到最差的链接类型为const、eq_reg、ref、range、index 和 ALL</p>

<p>possible_keys：        显示可能应用这张表中的索引。如果为空，没有可能的索引。</p>

<p>Key：                  实际使用的索引。如果为NULL，则没有使用索引；</p>

<p>key_len：              使用索引的长度。在不损失精确性的情况下，长度越短越好；</p>

<p>ref：                  显示索引的哪一列被使用了，如果可能的话，是一个常数</p>

<p>rows：                 MYSQL认为必须检查的用来返回请求数据的行数</p>

<br/>


<h3>Max优化：</h3>

<p>对max字段使用索引，优化了explain的type；</p>

<h3>子查询的优化：</h3>

<p>通常情况下，把子查询优化成join，要注意是否一对多的关系，注意重复数据</p>

<h3>Limit优化：</h3>

<p>limit常用于分页操作，时常会伴随order by 从句使用，因此会使用 filesorts 这样会造成大量IO问题；</p>

<h4>优化步骤1：</h4>

<p>使用主键，或者索引列来进行Order by 操作；</p>

<h4>优化步骤2：</h4>

<p>记录上次返回主键，在下次查询使用主键过滤；【如果主键不是顺序增长的，有空缺，则返回的数量每页可能变少】，避免了数据量大时扫描过多的记录</p>

<br/>


<br/>




<h2 id="2.3">三、建立索引</h2>


<hr />

<h3 id="2.3.1"> 3.1 如何选择合适的列建立索引：</h3>


<hr />

<br/>


<p>1.在where从句，group by从句，order by从句，on从句出现的列；</p>

<p>2.索引字段越小越好；</p>

<p>3.离散度越大的列放在联合索引前面；</p>

<br/>


<p><code>sql
select * from payment where staff_id = 2 and customer_id = 584;
</code></p>

<br/>


<p>是 index(staff_id, customer_id) 好？还是 index(customer_id, staff_id) 好？</p>

<br/>


<p>由于 customer_id 的离散度更大，所以应该使用 index(customer_id, staff_id)
那么如何知道离散程度：
可以通过一下查询：</p>

<p><code>sql
select count(distinct customer_id), count(distinct staff_id) from payment;
</code></p>

<p><img src="/images/posts/2018-05-12/%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E7%A6%BB%E6%95%A3%E5%BA%A6.gif" alt="联合索引离散度" /></p>

<br/>


<p>得到staff_id比较集中，离散程度比较好，所以选择 customer_id 来作为联合索引前面的字段；</p>

<br/>




<h3 id="2.3.2"> 索引的维护和优化—重复及冗余索引</h3>


<p>重复的索引是指相同的列以相同的顺序建立的同类型的索引，如下表的 unique 索引中包含了 primary key 索引</p>

<p><code>sql
create table test (
  id int not null primary key,
  name varchar(10) not null,
  title varchar(50) not null,
  Unique(name, id)
)engine=innodb;
</code></p>

<p>使用pt-duplicate-key-checker工具检查重复及冗余索引</p>

<p><code>sql
pt-duplicate-key-checker -uroot -p -h127.0.0.1
</code></p>

<br/>


<br/>




<h3 id="2.3.3"> 删除不用索引：</h3>


<p> mysql没有记录索引使用情况，但在PerconMysql，MariaDB中有INDEX_STATISTICS表来查看哪些索引未使用，但在mysql中目前只能通过慢查询日志来配合 pt-index-usage 工具来进行索引使用情况分析；</p>

<p><code>sql
pt-index-usage -uroot -p mysql-slow.log
</code></p>

<h2 id='2.4'>四、系统配置优化：</h2>


<hr />

<p>Mysql 配置文件-常用参数说明</p>

<p><code>sql
Innodb_buffer_pool_size
</code></p>

<p>配置innodb的缓冲池，如果数据库中只有innodb表，则推荐配置量为总内存的75%；</p>

<br/>


<p><code>sql
innodb_buffer_pool_instances
</code></p>

<p>可以控制缓冲池的个数，默认一个缓冲池</p>

<br/>


<p><code>sql
innodb_log_buffer_size
</code></p>

<p>Innodb log 缓冲的大小，由于日志最长每秒就会刷新所以一般不用太大；</p>

<br/>


<p><code>sql
innodb_flush_log_at_trx_commit
</code></p>

<p>关键参数，对 innodb 影响很大。默认值为1，可以取0，1，2三个值，一般建议设为2，如果安全性要求高则使用默认值1；</p>

<br/>


<p><code>sql
innodb_read_io_threads
Innodb_write_io_threads
</code>
读写io进程数，默认为4；</p>

<br/>


<p><code>sql
innodb_file_per_table
</code></p>

<p>关键参数，控制 Innodb 每个表使用独立的表空间，默认为OFF，也就是所有表会建立在共享表空间中，IO 会形成瓶颈；
建议设置为 ON，这样每个使用独立的共享表空间；</p>

<br/>


<p><code>sql
Innodb_stats_on_metadata
</code>
决定 mysql 什么情况下会刷新 innodb 表的统计信息；</p>

<p>上述信息可以使用 Per Configuration Wizard 配置</p>

<br/>


<br/>




<h1 id="3">硬件要求：</h1>


<hr />

<p>如何选择CPU</p>

<ol>
<li><p>Mysql一些工作只能用单核CPU：   SQL语句执行，Replicate；</p></li>
<li><p>Mysql对核数并不是越多越好：mysql5.5 不要超过32核；</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用select union join 解决分页与排序的矛盾]]></title>
    <link href="https://TsaiKoga.github.com/blog/2017/10/02/li-yong-select-union-join-jie-jue-fen-ye-yu-pai-xu-de-mao-dun/"/>
    <updated>2017-10-02T18:34:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2017/10/02/li-yong-select-union-join-jie-jue-fen-ye-yu-pai-xu-de-mao-dun</id>
    <content type="html"><![CDATA[<p>刚入职新公司的时候，被数据库的设计吓了一跳；要在一个有缺陷的数据库上解决数据量很大而导致的查询速度慢问题。</p>

<p>首先，先来讲一下这个场景，这是一个APP的交易页面，他要显示的列表信息是衣服的款号，在这款号下面有这个款的几个SKU
（颜色尺码），以及SKU对应的销售量和交易额。</p>

<p><img src="/images/posts/2017-10-02/mysql-view.jpg" title="视图场景" alt="视图场景" /></p>

<p>然后，数据库中有三个单据表：开单OrderCreate，改单OrderModification，退货单ReturnGoods；
这三张表各有三个子表 开单子表OrderCreateGoodsSku，改单子表OrderModificationGoodsSku，退货子表ReturnGoodsSku；
这些子表都有对应的goods_count和goods_price，分别代表着交易数量和单价；他们都对应这一张交易单表 transaction；</p>

<p>所以，销售量是（开单+改单-退货）的goods_count，
交易额是（开单goods_count * 开单goods_price + 改单goods_count * 改单goods_price &ndash; 退货goods_count * 退货goods_price)
当然，由于还要显示颜色尺码以及款号，我们还需要去join 有这些字段的表才行。</p>

<p>一开始入职时，觉得这三张表其实字段基本相同，可以将它放在一张表中，使用 type 字段做区分，类似于 ruby on rails 中的单表继承；
这样，算销量 和 销售价 就从这张表出发 join sku 就可以了，这样可比分三张要快；</p>

<p>后来数据量比较大时，也会想，这样也许是为了分表，减少数据在单张表的数量；
transaction 做为主表，分别被 create_order 开单、modification_order 改单 和 return_goods 退货关联；
不过分表可能要根据业务逻辑，如果是页面中有对单独类型显示，可以用这种分法，不过一般还是对时间的依赖性比较强；</p>

<p>回过头来，我们继续看看这三张主要单据：</p>

<p>由于全部时间单据实在太多，一次性找出来构造成所需要的形式也很耗时；再者，随着时间推移，单据越来越多，这查询速度就更加不能接受了。</p>

<p>所以应该使用分页解决。但是这里还有一个需求，就是要根据交易额和销售量排序。也就是三张表查出的数据进行计算后的结果集进行排序。</p>

<p>但是这样就无法真正意义上的分页了，所以有没有办法 <strong>在排序后，取出结果集前进行分页</strong> 呢？</p>

<p>CTO建议使用视图。</p>

<h3>什么是视图</h3>

<hr />

<p>视图是一个 <strong>虚拟表</strong>，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。
但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在 <strong>引用视图时动态生成</strong>。</p>

<p>视图只是一段逻辑。</p>

<h3>使用视图解决排序与分页的矛盾</h3>

<p>现在我们只需要把三张子表的内容全部 union 成一张虚拟表就行了</p>

<p><code>sql
CREATE ALGORITHM=UNDEFINED DEFINER=`juniu`@`%` SQL SECURITY DEFINER VIEW `juniu_transfer` AS
(select `juniu_order_create_goods_sku`.`goods_id` AS `goods_id`,`juniu_order_create_goods_sku`.`goods_count` AS `goods_count`,`juniu_order_create_goods_sku`.`goods_price` AS `goods_price`,`juniu_order_create_goods_sku`.`goods_sku_id` AS `goods_sku_id`,`juniu_order_create_goods_sku`.`store_id` AS `store_id`,`juniu_order_create_goods_sku`.`customer_id` AS `customer_id`,`juniu_order_create_goods_sku`.`seller_user_id` AS `seller_user_id`,`juniu_order_create_goods_sku`.`operate_user_id` AS `operate_user_id`,`juniu_order_create_goods_sku`.`timestamp` AS `timestamp`,`juniu_order_create_goods_sku`.`transaction_id` AS `transaction_id`,`juniu_order_create_goods_sku`.`dev_flag` AS `dev_flag`,`juniu_order_create_goods_sku`.`deleted_at` AS `deleted_at`
 from `juniu_order_create_goods_sku`)
union all
(select `juniu_order_modification_goods_sku`.`goods_id` AS `goods_id`,`juniu_order_modification_goods_sku`.`goods_count_diff` AS `goods_count_diff`,`juniu_order_modification_goods_sku`.`goods_price` AS `goods_price`,`juniu_order_modification_goods_sku`.`goods_sku_id` AS `goods_sku_id`,`juniu_order_modification_goods_sku`.`store_id` AS `store_id`,`juniu_order_modification_goods_sku`.`customer_id` AS `customer_id`,`juniu_order_modification_goods_sku`.`seller_user_id` AS `seller_user_id`,`juniu_order_modification_goods_sku`.`operate_user_id` AS `operate_user_id`,`juniu_order_modification_goods_sku`.`timestamp` AS `timestamp`,`juniu_order_modification_goods_sku`.`transaction_id` AS `transaction_id`,`juniu_order_modification_goods_sku`.`dev_flag` AS `dev_flag`,`juniu_order_modification_goods_sku`.`deleted_at` AS `deleted_at`
  from `juniu_order_modification_goods_sku`)
union all
(select `juniu_return_goods_sku`.`goods_id` AS `goods_id`,(-(1) * `juniu_return_goods_sku`.`goods_count`) AS `-1*goods_count`,`juniu_return_goods_sku`.`goods_price` AS `goods_price`,`juniu_return_goods_sku`.`goods_sku_id` AS `goods_sku_id`,`juniu_return_goods_sku`.`store_id` AS `store_id`,`juniu_return_goods_sku`.`customer_id` AS `customer_id`,`juniu_return_goods_sku`.`seller_user_id` AS `seller_user_id`,`juniu_return_goods_sku`.`operate_user_id` AS `operate_user_id`,`juniu_return_goods_sku`.`timestamp` AS `timestamp`,`juniu_return_goods_sku`.`transaction_id` AS `transaction_id`,`juniu_return_goods_sku`.`dev_flag` AS `dev_flag`,`juniu_return_goods_sku`.`deleted_at` AS `deleted_at`
  from `juniu_return_goods_sku`);
</code></p>

<p>这就是创建的视图，它有了我们想要的goods_count和goods_price，并且将ReturnGoodsSku的goods_count改为了负数，这样我们可以一次性SUM起来，
实现交易额和销量的运算；</p>

<p>然后在取出所有数据之前对结果集进行排序。最后通过top或limit取出来；</p>

<p>你也可以先建立这个视图的Model，然后就可以通过ORM来获取结果集。</p>

<p>最后，说说效果，其实效果不能接受，因为三张表的数据 union all 后数据量太庞大，导致加载速度还是非常非常慢，union all时间实在太长了；
mysql 视图又无法使用索引；所以鱼与熊掌不可得兼。</p>

<h3>使用 select union join as 解决排序与分页的矛盾</h3>

<p>那么该怎么办呢，我是可以试图把union all的数据减少，也就是先用 where 进行筛选然后再 union all；
然后对这些已经筛选并且合并的数据进行 join 关联操作（这样可以 <strong>大大减少 join 关联的内容</strong>）；
最后再次将他们 select 出来：</p>

<p>其实分表后也是这样来汇集所有分表的数据到一张表的，算是分表的一种查询操作吧：</p>

<p>``` sql
SELECT</p>

<pre><code>g.goods_id,
SUM(t.saleVolumn) AS saleVolumn
</code></pre>

<p>FROM</p>

<pre><code>juniu_goods AS g
</code></pre>

<p>LEFT JOIN (</p>

<pre><code>(
    SELECT
        c.goods_id AS goods_id,
        c.goods_count AS goods_count,
        c.goods_price AS goods_price,
        sum(
            c.goods_count * c.goods_price
        ) AS saleVolumn,
        c.goods_sku_id AS goods_sku_id,
        c.store_id AS store_id,
        c.customer_id AS customer_id,
        c.seller_user_id AS seller_user_id,
        c.operate_user_id AS operate_user_id,
        c. TIMESTAMP AS TIMESTAMP,
        c.transaction_id AS transaction_id,
        c.dev_flag AS dev_flag,
        c.deleted_at AS deleted_at,
        'create' AS order_type,
        0 AS return_count
    FROM
        juniu_order_create_goods_sku AS c
    WHERE
        c.store_id = 651
    GROUP BY
        goods_id
)
UNION ALL
    (
        SELECT
            m.goods_id AS goods_id,
            m.goods_count_diff AS goods_count_diff,
            m.goods_price AS goods_price,
            sum(
                m.goods_count_diff * m.goods_price
            ) AS saleVolumn,
            m.goods_sku_id AS goods_sku_id,
            m.store_id AS store_id,
            m.customer_id AS customer_id,
            m.seller_user_id AS seller_user_id,
            m.operate_user_id AS operate_user_id,
            m. TIMESTAMP AS TIMESTAMP,
            m.transaction_id AS transaction_id,
            m.dev_flag AS dev_flag,
            m.deleted_at AS deleted_at,
            'modification' AS order_type,
            0 AS return_count
        FROM
            juniu_order_modification_goods_sku AS m
        WHERE
            m.store_id = 651
        GROUP BY
            goods_id
    )
UNION ALL
    (
        SELECT
            r.goods_id AS goods_id,
            (- 1 * r.goods_count) AS goods_count,
            r.goods_price AS goods_price,
            sum(- 1 * r.goods_price) AS saleVolumn,
            r.goods_sku_id AS goods_sku_id,
            r.store_id AS store_id,
            r.customer_id AS customer_id,
            r.seller_user_id AS seller_user_id,
            r.operate_user_id AS operate_user_id,
            r. TIMESTAMP AS TIMESTAMP,
            r.transaction_id AS transaction_id,
            r.dev_flag AS dev_flag,
            r.deleted_at AS deleted_at,
            'return' AS order_type,
            r.goods_count AS return_count
        FROM
            juniu_return_goods_sku AS r
        WHERE
            r.store_id = 651
        GROUP BY
            goods_id
    )
</code></pre>

<p>) AS t ON g.goods_id = t.goods_id
WHERE</p>

<pre><code>g.store_id = 651
</code></pre>

<p>GROUP BY</p>

<pre><code>g.goods_id
</code></pre>

<p>ORDER BY</p>

<pre><code>saleVolumn DESC
</code></pre>

<p>LIMIT 0,
 20
```
这个效果拔群！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql索引]]></title>
    <link href="https://TsaiKoga.github.com/blog/2017/10/02/mysqlsuo-yin/"/>
    <updated>2017-10-02T18:05:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2017/10/02/mysqlsuo-yin</id>
    <content type="html"><![CDATA[<h4><a href="#1">1.索引的优缺点原因</a></h4>

<h5><a href="#1.1">1.1为什么添加索引，查询速度变快</a></h5>

<h5><a href="#1.2">1.2为什么添加上索引，速度会变慢</a></h5>

<h4><a href="#2">2.索引的类别</a></h4>

<h5><a href="#2.1">2.1主键索引</a></h5>

<h5><a href="#2.2">2.2唯一索引</a></h5>

<h5><a href="#2.3">2.3普通索引</a></h5>

<h5><a href="#2.4">2.4多列索引</a></h5>

<h5><a href="#2.5">2.5全文索引</a></h5>

<h4><a href="#3">3.加索引情况</a></h4>

<h5><a href="#3.1">3.1 关键词</a></h5>

<h5><a href="#3.2">3.2 小技巧</a></h5>

<h4><a href="#4">4.索引生成文件</a></h4>

<h5><a href="#4.1">4.1 索引文件</a></h5>

<br/>


<p>之前一直对索引没有很清晰的认识，每次一创建表时，就给外键加索引，只知道索引提高mysql搜索效率；
前阵子查阅了很多资料，有了比较清晰的认识，现在给出如下总结：</p>

<br/>




<h2 id='1'>索引的优缺点原因</h2>


<hr />

<h3 id='1.1'>为什么添加索引，查询速度变快</h3>


<hr />

<p>计算机查找某一条记录，如果不加索引，会在整个表中一条一条比较，将匹配的记录加入 <strong>结果集</strong>，很多人说这样会很慢，加了索引就快了。</p>

<p>为什么？</p>

<p>计算机先在索引列表中找到记录的 <strong>位置</strong>，既 <strong>rowid</strong>，然后直接去表中的对应位置取出记录，我就不明白了，查找索引列表难道不需要一条一条的匹配？计算机又不会出现说，看索引列表比直接看表中的记录要快，先在索引列表中找到记录对应的 rowid 也是要遍历的？难道不是同样的吗？</p>

<br/>


<p>Mysql 索引主要两种：</p>

<br/>


<p><strong>1.BTree</strong>
取中间数作为根，比根小的数再取中间数放左边，大数放右边作为右边树叶；
时间复杂度就是log2(n)；</p>

<br/>


<p><strong>2.Hash</strong>
key-value 保存;
时间复杂度是(n);
缺点：不支持范围查询，只能指定查询；</p>

<br/>


<br/>




<h3 id='1.2'>为什么添加上索引，速度会变慢</h3>


<hr />

<ol>
<li><p>DML 耗时：根据上面的回答，添加索引会 <strong>构建 BTree </strong>，建立 <strong>索引都需要维护</strong>，你  <strong>创建、插入或删除</strong> 记录，都要重新构建部分 BTree；
【所以唯一性太差的字段不适合创建索引；字段频繁变化的字段也不适合创建索引】</p></li>
<li><p>消耗磁盘空间；</p></li>
</ol>


<br/>


<br/>




<h2 id='2'>索引的类别</h2>


<hr />

<h3 id='2.1'>主键索引</h3>


<hr />

<p>添加PRIMARY KEY（主键索引）</p>

<p><code>sql
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )
</code></p>

<br/>


<h3 id='2.2'>唯一索引</h3>


<hr />

<p>添加UNIQUE(唯一索引)</p>

<p><code>sql
ALTER TABLE `table_name` ADD UNIQUE ( `column` )
</code></p>

<p><strong>唯一索引中 null 不代表重复，可以有多个 null；</strong></p>

<br/>


<h3 id='2.3'>普通索引</h3>


<hr />

<p>添加INDEX(普通索引)</p>

<p><code>sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column`)
</code></p>

<br/>


<h3 id='2.4'>多列索引</h3>


<hr />

<p>也叫联合索引；
添加多列索引</p>

<p><code>sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`,`column2`, `column3` )
</code>
一般用在 where 几个字段，并且使用频繁的语句；
当使用联合索引后，第一个 column1 将是一级目录，所以不用单独给它做索引，因为他已经是单独的索引了；</p>

<p>第二个 column2 是二级目录索引，所以如果你也可以增加多一个单独索引，因为不可能直接使用二级目录的；</p>

<br/>


<h3 id='2.5'>全文索引</h3>


<hr />

<p>添加FULLTEXT(全文索引)</p>

<p>全文索引只能在 <strong>MYISAM</strong> 引擎中使用：</p>

<p><code>sql
ALTER TABLE `table_name` ADD FULLTEXT (`column`)
</code></p>

<h4>如何使用：</h4>

<p>在MySQL中创建全文索引之后，现在就该了解如何使用了。众所周知，在数据库中进行模糊查询是使用LIKE关键字进行查询，例如：
<code>sql
SELECT * FROM article WHERE content LIKE '%查询字符串%'
</code></p>

<p>那么，我们使用全文索引也是这样用的吗？当然不是，我们必须使用特有的语法才能使用全文索引进行查询。例如，我们想要在article表的title和content列中全文检索指定的查询字符串，可以如下编写SQL语句：</p>

<p><code>sql
SELECT * FROM article WHERE MATCH(title, content) AGAINST('查询字符串')
</code></p>

<p>PS: 全文索引并不是所有文本都加索引，而是通过“停止词”；
对一些常用词，没什么特殊含义的词（a, the, at, which, want&hellip;）不加索引，这些词叫做停止词；</p>

<br/>




<h3 id='2.6'>查询、修改、删除索引</h3>


<hr />

<p>1.查询
desc 表名;【该方法的缺点，不能显示索引名】
<code>sql
show index from 表名;
show keys from 表名;
</code></p>

<br/>


<p>2.删除
<code>sql
alter table 表名 drop index 索引名;
如果删除主键索引：
alter table 表名 drop primary key;
</code></p>

<br/>


<p>3.修改</p>

<p>先删除，再重新创建；</p>

<br/>


<br/>




<p><h2 id='3'>加索引的情况</h3></p>

<p><h3 id='3.1'> 关键词 </h3>
一些关键词代表可能会经常用到索引，具体还是要把 SQL 语句从程序中 debug 出来，
然后在 mysql 中查看用 explain 是否有用到该索引：</p>

<p>1.分组字段：
<code>sql
group by
</code>
很多人觉得不会用到，其实会用到的；
按照 explain 可以看出单独对驱动表使用 group by，mysql 计划是会使用索引的；
<code>
explain
select *
from juniu_return_goods_sku
group by juniu_return_goods_sku.goods_id
</code>
这里返回使用了索引，并且不会 用到 using temporary;
所以加了索引，用 explain 验证一下即可；</p>

<p>2.排序字段：
<code>sql
order by
</code></p>

<p>3.统计字段，【注意运算不会用索引，例如:SUM, YEAR】：
<code>sql
select MAX()
</code></p>

<p>4.主键外键字段：
<code>sql
JOIN()
</code></p>

<p>还有要注意无效索引：</p>

<p>1.运算字段：
<code>sql
WHERE DATE_FORMATE(created_at, '%Y/%m%/d') = '2018-05-12'
</code></p>

<p>2.Like语句：
<code>sql
like "%aaa%" // 不会用到索引
like "aaa%" // 会用到索引
</code></p>

<p>3.含有NULL值的列【注意：给默认值】</p>

<p>4.NOT IN语句【注意：可以改成 NOT EXISTS】：
<code>sql
WHERE id NOT IN (1,2,3);
</code></p>

<p>5.OR 语句：
<code>sql
WHERE id = 1 OR id = 2;
</code></p>

<p>它先对日期值使用 DATE_FORMATE 方法，所以索引无效；</p>

<p><br/>
<br/></p>

<p><h3 id='3.2'> 小技巧 </h3></p>

<ol>
<li><p>在使用 <strong>group by</strong> 分组查询时，默认分组后，还会排序，可能会降低速度；
例如：在一张表中对一个索引字段进行 group by ，explain后发现他不会使用索引，但是 extra 中有 <strong>Using filesort</strong>；
解决：group by 后面加上 <strong>order by null</strong>;</p></li>
<li><p>有些情况下，可以使用连接代替子查询。
因为使用 join，Mysql 不需要在 <strong>内存</strong> 中创建 <strong>临时表(不使用索引)</strong>，
除非指定了联接条件时，满足查询条件的记录行数少的表为[驱动表]，未指定联接条件时，行数少的表为[驱动表]，多表联合查询时</p></li>
</ol>


<p><code>sql
select * from dept, emp where dept.no = emp.no; // 简单处理方式
select * from dept left join emp on dept.no = emp.no; // 左连接
</code></p>

<p><br/>
<br/></p>

<p><h2 id='4'>4. 索引生成文件</h2></p>

<p><h3 id='4.1'>索引文件</h3></p>

<p>可以通过 my.ini 看到索引的目录文件，一般每一张表有三个文件：
&ndash; .frm 记录表的结构，【innodb 数据库的数据放在外层目录的 ibdata 文件；】</p>

<ul>
<li><p>.myd 表的数据</p></li>
<li><p>.myi 记录表的索引</p></li>
</ul>


<p><br/>
<br/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails 利用批量操作提速]]></title>
    <link href="https://TsaiKoga.github.com/blog/2016/08/21/rails-li-yong-pi-liang-cao-zuo-ti-su/"/>
    <updated>2016-08-21T14:29:00+08:00</updated>
    <id>https://TsaiKoga.github.com/blog/2016/08/21/rails-li-yong-pi-liang-cao-zuo-ti-su</id>
    <content type="html"><![CDATA[<h4><a href="#1.1">1.1 批量查找数据</a></h4>

<h5><a href="#1.2">1.2 操作代码</a></h5>

<h4><a href="#2.1">2.1 批量插入数据</a></h4>

<h5><a href="#2.2">2.2 INFILE文件插入数据</a></h5>

<h4><a href="#3.1">3.1 批量更改schema数据库</a></h4>

<h2 id="1.1">1.1 批量查找数据</h2>


<hr />

<p>由于之前一直在做后台的数据，其中有个任务是关于 财务库存 的页面.</p>

<blockquote><p>这个“财务库存”有产品和日期选项，您可以通过选择产品，查看它在某段时间内的库存价格等情况。</p>

<p>将采购入库单数据[PurchaseOrderBill]，销售出库单数据[OutStorageOrder]，异常取货和仓库调整单数据整合在一个页面；
根据日期排序来显示这个页面的内容，以及这些内容的成本价格变化，这里的价格根据这些取出来的数据进行排列后再进行运算得出。</p>

<p>项目中有近5w条产品记录，又要将“采购入库单”和“销售出库单”与 产品product进行关联查找，耗时挺大的。</p>

<p>这时候公司那边说要提供一次性下载所有产品的财务库存数据，不过不需要显示价格变化情况，直接显示最后一条价格结果就行了。</p></blockquote>

<p>近5w条的 product 产品关联(joins/includes)的单据进行计算价格，然后显示结果。
如何加快查找速度呢？</p>

<p>答案是进行 <strong>批量</strong> 查找。</p>

<h3 id="1.2">1.2 操作代码</h3>


<p>用代码说明吧，首先当然对于这么庞大的数据量，要进行 <strong>分页</strong> 处理：
``` ru</p>

<pre><code>per_page = 100
page = 0
total_page = (Product.count.to_f / per_page).ceil
</code></pre>

<p>```</p>

<p>每一页进行 <strong>批量</strong> 操作：
``` ru</p>

<pre><code>total_page.times do
  products = Product.limit(per_page).offset(page * per_page)
  bill_items = bill_inventory_valuation_details products        # 符合条件的采购入库单数据，此方法的查找也必须对 products 进行批量查找
  sell_items = sell_inventory_valuation_details products        # 符合条件的销售出库数据
  package_items = package_inventory_valuation_details products  # 异常出库数据
  adjust = adjust_inventory_valuation_details products          # 调整仓库数据
  products.each do |product|
    datas = []
    datas += bill_items[product.id].map{|item| {id: item.id, quantity: item.quantity, price: item.price}}
    # 对查出的数据进行处理，构造最终结果
    ... ...
  end
end
</code></pre>

<p>```</p>

<p>批量的产品分别进行采购单Bill,销售单Sell，包裹Package，还有调整库存单据Adjust的查询然后全部group_by产品ID，
最后将以产品ID来循环，将这个产品的所有单据组合一起，然后就可以算它的库存销售情况。
<strong>记住：代码循环永远比循环数据库操作要快的多</strong></p>

<p>``` ru
def bill_inventory_valuation_details products</p>

<pre><code>bill_items = PurchaseOrderBillItem.joins(:purchase_order_bill =&gt; :purchase_order).
                                   includes(:purchase_order_bill =&gt; :purchase_order).
                                   where("purchase_order_bills.status = ?", PurchaseOrderBill::STATUS[:finished]).
                                   where("purchase_order_bills.date BETWEEN ? AND ?", @start_date, @end_date).
                                   where("purchase_order_bill_items.product_id IN (?)", products.pluck(:id)).
                                   group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def sell_inventory_valuation_details products</p>

<pre><code>sell_items = OutStorageOrderItem.joins(:out_storage_order).
                                 includes(:out_storage_order).
                                 where("out_storage_orders.out_storage_order_type = ?", 3).
                                 where("out_storage_orders.created_at BETWEEN ? AND ?", @start_date.beginning_of_day, @end_date.end_of_day).
                                 where("out_storage_orders.package_id IS NOT NULL OR out_storage_orders.package_group_id IS NOT NULL").
                                 where("out_storage_order_items.product_id IN (?)", products.pluck(:id)).
                                 group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def adjust_inventory_valuation_details products</p>

<pre><code>adjust = AdjustInventoryRecord.where("the_date BETWEEN ? AND ?", @start_date, @end_date).where(product_id: products.pluck(:id)).group_by(&amp;:product_id)
</code></pre>

<p>  end</p>

<p>  def package_inventory_valuation_details products</p>

<pre><code>package_items = PackageItem.eager_load(:package).where(product_id: products.pluck(:id)).
                                              where("packages.state = ?", Package::STATE_VALUES[:processed]).
                                              where("packages.dropship = ?", false).
                                              where("packages.shipped_at &gt;= ? AND packages.shipped_at &lt;= ?", @start_date, @end_date).group_by(&amp;:product_id)
</code></pre>

<p>  end
```</p>

<p>这样原先没有进行批量操作会耗时接近12个小时，使用了批量操作后仅为2个多小时。</p>

<h2 id="2.1">2.1 批量插入数据</h2>


<hr />

<p>当你要对大量数据进行插入数据库的操作时，一条条插入将是及其愚蠢的行为。如何进行批量插入呢？</p>

<p>可以先看看这篇文章：<a href="https://www.coffeepowered.net/2009/01/23/mass-inserting-data-in-rails-without-killing-your-performance/">Mass inserting data in Rails without killing your performance</a></p>

<p>这篇文章提到 Rails 快速插入数据的四种方法：</p>

<ol>
<li><p>Use transactions</p></li>
<li><p>Get down and dirty with the raw SQL</p></li>
<li><p>A single mass insert</p></li>
<li><p>Use INSERT statements with multiple VALUES lists with ar-extensions OR activerecord-import</p></li>
</ol>


<p>第四种方式是AR方式的70倍左右，而公司后台使用的正是 activerecord-import,
做法很简单，先将数据创建 <strong>存于内存</strong>，然后批量 import <strong>插入</strong> 数据库：</p>

<p>``` ru</p>

<pre><code>(controller.action_methods.to_a - excepts).each do |action|
  need_imports &lt;&lt; Permission.new(subject: subject, action: action, description: "#{action.humanize} of #{subject}")
end
Permission.import need_imports
</code></pre>

<p>```</p>

<p>这样已经很快了，还有更快的吗？</p>

<h3 id="2.2">2.2 INFILE文件插入数据 </h3>


<p>From MySQL Doc:</p>

<blockquote><p>When loading a table from a text file, use LOAD DATA INFILE. This is usually 20 times faster than using INSERT statements</p></blockquote>

<p>SQL语句：</p>

<p><code>
(15955.1ms)  LOAD DATA LOCAL INFILE '/Users/tsaikoga/out_storage_orders.txt'
REPLACE INTO TABLE out_storage_orders FIELDS TERMINATED BY ',' (`id`,`warehouse_id`,`destination_id`,`user_id`,`out_storage_order_type`,`out_storage_reason_type`,`status`,`quantity`,`package_id`)
</code></p>

<p>插入行数：</p>

<p>``` sh</p>

<pre><code>wc -l &lt; /Users/tsaikoga/out_storage_orders.txt
100000
</code></pre>

<p>```</p>

<h3 id="3.1">3.1 批量更改schema数据库</h3>


<hr />

<p>你有没有发现，当你某张表的数据非常非常多的时候，你想要更改其中一个字段的类型，然后执行 migrate ；
执行时间非常长，你厌倦了等待，只好 ctrl+c 撤销了migrate，但是实际上数据库中的记录已经有很大一部分改变了字段的类型。
这时候你想再migrate，会出现这种类型的字段已存在的提示。（当然你可以利用mysql的界面工具或直接到mysql更改字段类型进行拯救）</p>

<p>这里提供一个 Rails 的方法，将数据大批量进行更改。
比方说，以下是一段更改 orders 表的 shipping_first_name shipping_last_name 名称的方法：</p>

<pre><code>rename_column :orders, "shipping_first_name", "origin_shipping_first_name"
rename_column :orders, "shipping_last_name", "origin_shipping_last_name"
</code></pre>

<p>执行migrate用时非常长，还不如使用如下代码：</p>

<p>``` ru</p>

<pre><code>class RenameOldOrderAddressRelatedColumn &lt; ActiveRecord::Migration
  def up
    change_table(:orders, :bulk =&gt; true) do |t|
      t.rename :order_status_code_id, :state
      t.remove :in_process
      [:first_name,
       :last_name,
       :country,
       :state].each do |column|
        t.rename "shipping_#{column}", "origin_shipping_#{column}"
      end
    end
  end
end
</code></pre>

<p>```</p>

<p>以上代码只生成一句 SQL 语句，数据库迁移时间大大减少。</p>

<p>```</p>

<pre><code>ALTER TABLE `orders` DROP `in_process`, CHANGE `shipping_first_name` `origin_shipping_first_name` varchar(50) DEFAULT NULL, CHANGE `shipping_last_name` `origin_shipping_last_name` varchar(50) DEFAULT NULL, CHANGE `shipping_country` `origin_shipping_country` varchar(255) DEFAULT NULL, CHANGE `shipping_state` `origin_shipping_state` varchar(255) DEFAULT NULL...
</code></pre>

<p>```</p>

<p>相关文档：</p>

<p><a href="http://dev.mysql.com/doc/refman/5.5/en/load-data.html">http://dev.mysql.com/doc/refman/5.5/en/load-data.html</a>
<a href="http://dev.mysql.com/doc/refman/5.5/en/insert-speed.html">http://dev.mysql.com/doc/refman/5.5/en/insert-speed.html</a></p>

<p>总结，对于大数据一定要进行批量处理。</p>
]]></content>
  </entry>
  
</feed>
